{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e50b347a",
   "metadata": {},
   "source": [
    "# Utility notebook for extracting out confidence scores from boltz2 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b93412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# This script is designed to parse the results from boltz2 predictions, extract relevant data,\n",
    "# and save it in a structured format for further analysis.\n",
    "\n",
    "# Data output structure from boltz2\n",
    "\"\"\"\n",
    "So boltz2 outputs data in a directory structure like this:\n",
    "\n",
    "~/boltz_results_MIPS-0051357/predictions/MIPS-0051357\n",
    "\n",
    "in side this directory, there are multiple files , including the confidence scores per model:\n",
    "confidence_MIPS-0051357_model_0.json\n",
    "confidence_MIPS-0051357_model_1.json\n",
    "confidence_MIPS-0051357_model_2.json\n",
    "confidence_MIPS-0051357_model_3.json\n",
    "confidence_MIPS-0051357_model_4.json\n",
    "\n",
    "and the models themselves:\n",
    "MIPS-0051357_model_0.cif\n",
    "MIPS-0051357_model_1.cif\n",
    "MIPS-0051357_model_2.cif\n",
    "MIPS-0051357_model_3.cif\n",
    "MIPS-0051357_model_4.cif\n",
    "\n",
    "The confidence files are in JSON format, and look like this:\n",
    "{\n",
    "    \"confidence_score\": 0.8774623870849609,\n",
    "    \"ptm\": 0.7683840990066528,\n",
    "    \"iptm\": 0.8961464762687683,\n",
    "    \"ligand_iptm\": 0.8961464762687683,\n",
    "    \"protein_iptm\": 0.0,\n",
    "    \"complex_plddt\": 0.8727914094924927,\n",
    "    \"complex_iplddt\": 0.7528989315032959,\n",
    "    \"complex_pde\": 0.8251760005950928,\n",
    "    \"complex_ipde\": 2.783323049545288,\n",
    "    \"chains_ptm\": {\n",
    "        \"0\": 0.7612196803092957,\n",
    "        \"1\": 0.945591151714325\n",
    "    },\n",
    "    \"pair_chains_iptm\": {\n",
    "        \"0\": {\n",
    "            \"0\": 0.7612196803092957,\n",
    "            \"1\": 0.4030245244503021\n",
    "        },\n",
    "        \"1\": {\n",
    "            \"0\": 0.8961464762687683,\n",
    "            \"1\": 0.945591151714325\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def parse_boltz2_results(directory):\n",
    "    results = []\n",
    "    print(f\"Scanning directory: {directory}\")  # Debugging statement\n",
    "    confidence_files = [f for f in os.listdir(directory) if f.startswith('confidence_') and f.endswith('.json')]\n",
    "    print(f\"Found confidence files: {confidence_files}\")  # Debugging statement\n",
    "\n",
    "    for conf_file in confidence_files:\n",
    "        model_index = conf_file.split('_')[-1].split('.')[0]  # Extract model index from filename\n",
    "        base_name = '_'.join(conf_file.split('_')[1:-2])\n",
    "        confidence_data = json.load(open(os.path.join(directory, conf_file), 'r'))  # Load the JSON data\n",
    "\n",
    "        # Find the corresponding model file dynamically based on the confidence file name\n",
    "        base_name = conf_file.replace('confidence_', '').replace(f'_model_{model_index}.json', '')\n",
    "        model_file = f\"{base_name}_model_{model_index}.cif\"\n",
    "        model_path = os.path.join(directory, model_file)\n",
    "        print(f\"Constructed model path: {model_path}\")  # Debugging statement\n",
    "\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"Model file exists: {model_path}\")  # Debugging statement\n",
    "            results.append({\n",
    "                'model_path': model_path,\n",
    "                'model_index': model_index,\n",
    "                'confidence_score': confidence_data['confidence_score'],\n",
    "                'ptm': confidence_data['ptm'],\n",
    "                'iptm': confidence_data['iptm'],\n",
    "                'ligand_iptm': confidence_data['ligand_iptm'],\n",
    "                'protein_iptm': confidence_data['protein_iptm'],\n",
    "                'complex_plddt': confidence_data['complex_plddt'],\n",
    "                'complex_iplddt': confidence_data['complex_iplddt'],\n",
    "                'complex_pde': confidence_data['complex_pde'],\n",
    "                'complex_ipde': confidence_data['complex_ipde'],\n",
    "                'chains_ptm': confidence_data['chains_ptm'],\n",
    "                'pair_chains_iptm': confidence_data['pair_chains_iptm']  \n",
    "            })\n",
    "        else:\n",
    "            print(f\"Model file does not exist: {model_path}\")  # Debugging statement\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Function to combine the CSV results from multiple files:\n",
    "def combine_csv_results(file_list):\n",
    "    combined_df = pd.concat([pd.read_csv(f) for f in file_list if f.endswith('_results.csv')])\n",
    "    return combined_df\n",
    "\n",
    "folder_list = os.listdir('./')\n",
    "\n",
    "print(f\"Found folders: {folder_list}\")  # Debugging statement\n",
    "\n",
    "for folder in folder_list:\n",
    "    if folder.startswith('boltz_results_'):\n",
    "        # Process only folders that start with 'boltz_results_'\n",
    "        # The .json files within this folder are two folders further up in the directory structure\n",
    "        # so we need to adjust the path accordingly\n",
    "        # For example, if the folder is 'boltz_results_MIPS-0051357', we will look for\n",
    "        # 'boltz_results_MIPS-0051357/predictions/MIPS-0051357'\n",
    "        # Adjust the path to point to the correct directory\n",
    "        predictions_folder = os.path.join(folder, 'predictions/', folder.split('_')[2])\n",
    "        if not os.path.exists(predictions_folder):\n",
    "            print(f\"Predictions folder does not exist: {predictions_folder}\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"working on folder: {predictions_folder}\")\n",
    "        print(f\"Processing folder: {predictions_folder}\")  # Debugging statement\n",
    "        results_df = parse_boltz2_results(os.path.join('./', predictions_folder))\n",
    "        # For example, to save it as a CSV file:\n",
    "        results_df.to_csv(f\"{folder}_results.csv\", index=False)\n",
    "    else:\n",
    "        print(f\"Skipping folder: {folder} (does not start with 'boltz_results_')\")\n",
    "\n",
    "# Combine all the CSV files into a single DataFrame\n",
    "\n",
    "file_list = [f for f in os.listdir('./') if f.endswith('_results.csv')]\n",
    "\n",
    "combined_df = combine_csv_results(file_list)\n",
    "combined_df.to_csv('boltz_results_combined.csv', index=False)\n",
    "print(\"Combined results saved to 'boltz_results_combined.csv'\")  # Debugging statement\n",
    "\n",
    "confidence_value = float(input((\"Enter the confidence value to filter results: \")))\n",
    "\n",
    "\n",
    "# Filtering the DataFrame to include only rows with a confidence score greater than 0.9 \n",
    "filtered_df = combined_df[combined_df['confidence_score'] > confidence_value]\n",
    "filtered_df.to_csv('boltz_results_filtered.csv', index=False)\n",
    "print(\"Filtered results saved to 'boltz_results_filtered.csv'\")  # Debugging statement\n",
    "\n",
    "# Using the filtered DataFrame to copy the corresponding .cif model files into a new directory\n",
    "output_dir = 'filtered_models'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "for index, row in filtered_df.iterrows():\n",
    "    model_path = row['model_path']\n",
    "    if os.path.exists(model_path):\n",
    "        # Copy the model file to the output directory\n",
    "        os.system(f\"cp {model_path} {output_dir}\")\n",
    "        print(f\"Copied {model_path} to {output_dir}\")\n",
    "    else:\n",
    "        print(f\"Model file does not exist: {model_path}\")  # Debugging statement\n",
    "\n",
    "# remove the temporary .csv files\n",
    "for file in file_list:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        print(f\"Removed temporary file: {file}\")  # Debugging statement\n",
    "    else:\n",
    "        print(f\"File does not exist: {file}\")  # Debugging statement\n",
    "\n",
    "\n",
    "# Copy all the .cif files from the combined results to a new directory\n",
    "combined_output_dir = 'combined_models'\n",
    "os.makedirs(combined_output_dir, exist_ok=True)\n",
    "for file in combined_df['model_path'].unique():\n",
    "    if os.path.exists(file):\n",
    "        # Copy the model file to the output directory\n",
    "        os.system(f\"cp {file} {combined_output_dir}\")\n",
    "        print(f\"Copied {file} to {combined_output_dir}\")\n",
    "    else:\n",
    "        print(prediction_id)\n",
    "        print(f\"File does not exist: {file}\")  # Debugging statement\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4af8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility to take the top confidence results for each prediction and match add them to a .csv file which has pharmacology data\n",
    "\n",
    "pharm_data1 = pd.read_csv('Series_1a_-_134_compounds.csv')\n",
    "pharm_data2 = pd.read_csv('Series_1b_-_500_compounds.csv')\n",
    "\n",
    "\n",
    "top_confidence_results_by_prediction = {}\n",
    "for index, row in combined_df.iterrows():\n",
    "    model_index = row['model_index']\n",
    "    model_path = row['model_path']\n",
    "    confidence_score = row['confidence_score']\n",
    "    ipTM = row['iptm']\n",
    "    plddt_score = row['complex_plddt']\n",
    "    \n",
    "    # Extract the prediction ID from the model path\n",
    "    prediction_id = os.path.basename(model_path).split('_')[0]\n",
    "    \n",
    "    if prediction_id not in top_confidence_results_by_prediction:\n",
    "        top_confidence_results_by_prediction[prediction_id] = {\n",
    "            'model_index': model_index,\n",
    "            'model_path': model_path,\n",
    "            'confidence_score': confidence_score,\n",
    "            'iptm': ipTM,\n",
    "            'plddt_score': plddt_score\n",
    "        }\n",
    "    else:\n",
    "        # If the prediction already exists, compare confidence scores\n",
    "        if confidence_score > top_confidence_results_by_prediction[prediction_id]['confidence_score']:\n",
    "            top_confidence_results_by_prediction[prediction_id] = {\n",
    "                'model_index': model_index,\n",
    "                'model_path': model_path,\n",
    "                'confidence_score': confidence_score,\n",
    "                'iptm': ipTM,\n",
    "                'plddt_score': plddt_score\n",
    "            }\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "top_confidence_df = pd.DataFrame.from_dict(top_confidence_results_by_prediction, orient='index').reset_index()\n",
    "top_confidence_df.rename(columns={'index': 'prediction_id'}, inplace=True)\n",
    "\n",
    "save_path = 'top_confidence_results_all_models.csv'\n",
    "top_confidence_df.to_csv(save_path, index=False)\n",
    "\n",
    "# Now need to merge this with the pharmacology data: Note that the pharmachology data has the prediction_id named 'Molecule Name'ArithmeticError\n",
    "# First merge the two pharmacology datasets\n",
    "pharm_data = pd.concat([pharm_data1, pharm_data2], ignore_index=True)\n",
    "\n",
    "# Merge the top confidence results with the pharmacology data\n",
    "merged_df = pd.merge(top_confidence_df, pharm_data, left_on='prediction_id', right_on='Molecule Name', how='left')\n",
    "# Save the merged DataFrame to a CSV file\n",
    "merged_save_path = 'top_confidence_results_with_pharm_data.csv'\n",
    "merged_df.to_csv(merged_save_path, index=False)\n",
    "print(f\"Top confidence results with pharmacology data saved to {merged_save_path}\")  #\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea9f12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ZIP archive of the important results for sharing\n",
    "# Path to the existing archive\n",
    "archive_name = f'boltz_results_archive_{confidence_value}'\n",
    "\n",
    "# Temporary directory to extract the archive\n",
    "temp_dir = 'temp_archive'\n",
    "\n",
    "# Copy the .csv files to the temporary directory\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "shutil.copy('boltz_results_combined.csv', temp_dir)\n",
    "shutil.copy('boltz_results_filtered.csv', temp_dir)\n",
    "shutil.copy('top_confidence_results_all_models.csv', temp_dir)\n",
    "shutil.copy('top_confidence_results_with_pharm_data.csv', temp_dir)\n",
    "\n",
    "# Copy the filtered_models directory to the temporary directory\n",
    "filtered_models_path = os.path.join(temp_dir, 'filtered_models')\n",
    "shutil.copytree('filtered_models', filtered_models_path, dirs_exist_ok=True)\n",
    "\n",
    "# Copy the combined_models directory to the temporary directory\n",
    "combined_models_path = os.path.join(temp_dir, 'combined_models')\n",
    "shutil.copytree('combined_models', combined_models_path, dirs_exist_ok=True)\n",
    "\n",
    "# Create the archive with the updated contents\n",
    "shutil.make_archive(archive_name, 'zip', temp_dir)\n",
    "\n",
    "# Clean up the temporary directory\n",
    "shutil.rmtree(temp_dir)\n",
    "\n",
    "\n",
    "print(\"Results Filtered and Collated comrade\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boltz2-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
