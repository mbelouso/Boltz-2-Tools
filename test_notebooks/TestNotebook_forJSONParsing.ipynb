{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d7ba0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "import modelcif.reader\n",
    "import modelcif\n",
    "import biotite\n",
    "import biotite.structure as struc\n",
    "import biotite.structure.io as strucio\n",
    "\n",
    "def parse_boltz2_results(directory):\n",
    "    results = []\n",
    "        \n",
    "    # Get confidence and affinity files\n",
    "    confidence_files = [f for f in os.listdir(directory) if f.startswith('confidence_') and f.endswith('.json')]\n",
    "    affinity_files = [f for f in os.listdir(directory) if f.startswith('affinity_') and f.endswith('.json')]\n",
    "    \n",
    "    # Create a dictionary to store affinity data by model key\n",
    "    affinity_dict = {}\n",
    "    \n",
    "    # Process affinity files first to build lookup dictionary\n",
    "    for aff_file in affinity_files:\n",
    "        base_name = aff_file.replace('affinity_', '').replace('.json', '')  # Extract base name\n",
    "        model_key = f\"{base_name}\"  # Key matches confidence file base name without `_model_0`\n",
    "        \n",
    "        try:\n",
    "            affinity_data = json.load(open(os.path.join(directory, aff_file), 'r'))\n",
    "            affinity_dict[model_key] = affinity_data\n",
    "            #print(f\"Loaded affinity data for key: '{model_key}' from file: {aff_file}\")  # Debugging statement\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading affinity file {aff_file}: {e}\")\n",
    "\n",
    "    # Process confidence files and merge with affinity data\n",
    "    for conf_file in confidence_files:\n",
    "        model_index = conf_file.split('_')[-1].split('.')[0]  # Extract model index from filename\n",
    "        base_name = conf_file.replace('confidence_', '').replace(f'_model_{model_index}.json', '')  # Extract base name\n",
    "        model_file = f\"{base_name}_model_{model_index}.pdb\"  # Assuming the model files are in PDB format\n",
    "        model_path = os.path.join(directory, model_file)\n",
    "        model_key = f\"{base_name}\"  # Key matches affinity file base name\n",
    "\n",
    "        # Load confidence data\n",
    "        try:\n",
    "            confidence_data = json.load(open(os.path.join(directory, conf_file), 'r'))\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading confidence file {conf_file}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        #print(f\"Processing confidence file: {conf_file}\")\n",
    "        #print(f\"Generated model key: '{model_key}'\")\n",
    "        #print(f\"Constructed model path: {model_path}\")  # Debugging statement\n",
    "\n",
    "        if os.path.exists(model_path):\n",
    "                        \n",
    "            # Create the result dictionary with confidence data\n",
    "            result_entry = {\n",
    "                'model_path': model_path,\n",
    "                'model_index': model_index,\n",
    "                'confidence_score': confidence_data['confidence_score'],\n",
    "                'ptm': confidence_data['ptm'],\n",
    "                'iptm': confidence_data['iptm'],\n",
    "                'ligand_iptm': confidence_data['ligand_iptm'],\n",
    "                'protein_iptm': confidence_data['protein_iptm'],\n",
    "                'complex_plddt': confidence_data['complex_plddt'],\n",
    "                'complex_iplddt': confidence_data['complex_iplddt'],\n",
    "                'complex_pde': confidence_data['complex_pde'],\n",
    "                'complex_ipde': confidence_data['complex_ipde'],\n",
    "                'chains_ptm': confidence_data['chains_ptm'],\n",
    "                'pair_chains_iptm': confidence_data['pair_chains_iptm']\n",
    "            }\n",
    "            \n",
    "            # Add affinity data if available for this model\n",
    "            if model_key in affinity_dict:\n",
    "                affinity_data = affinity_dict[model_key]\n",
    "                result_entry.update({\n",
    "                    'affinity_pred_value': affinity_data.get('affinity_pred_value', None),\n",
    "                    'affinity_probability_binary': affinity_data.get('affinity_probability_binary', None),\n",
    "                    'affinity_pred_value1': affinity_data.get('affinity_pred_value1', None),\n",
    "                    'affinity_probability_binary1': affinity_data.get('affinity_probability_binary1', None),\n",
    "                    'affinity_pred_value2': affinity_data.get('affinity_pred_value2', None),\n",
    "                    'affinity_probability_binary2': affinity_data.get('affinity_probability_binary2', None)\n",
    "                })\n",
    "                #print(f\"✓ Successfully added affinity data for: {model_key}\")  # Debugging statement\n",
    "            else:\n",
    "                # Add None values for affinity data if not available\n",
    "                result_entry.update({\n",
    "                    'affinity_pred_value': None,\n",
    "                    'affinity_probability_binary': None,\n",
    "                    'affinity_pred_value1': None,\n",
    "                    'affinity_probability_binary1': None,\n",
    "                    'affinity_pred_value2': None,\n",
    "                    'affinity_probability_binary2': None\n",
    "                })\n",
    "                print(f\"✗ No affinity data found for: '{model_key}'\")  # Debugging statement\n",
    "                print(f\"  Available keys: {list(affinity_dict.keys())}\")\n",
    "            \n",
    "            results.append(result_entry)\n",
    "    \n",
    "        else:\n",
    "            print(f\"Model file does not exist: {model_path}\")  # Debugging statement\n",
    "\n",
    "    #print(f\"\\nProcessed {len(results)} models total\")\n",
    "    print(f\"Affinity data matched for {sum(1 for r in results if r.get('affinity_pred_value') is not None)} models\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Function to combine the CSV results from multiple files:\n",
    "def combine_csv_results(file_list):\n",
    "    combined_df = pd.concat([pd.read_csv(f) for f in file_list if f.endswith('_results.csv')])\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de92dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_list = os.listdir('./') # Define the root folder where the boltz-2 output folders are located\n",
    "\n",
    "confidence_value = float(0.7) # Define the boltz-2 confidence value to filter results\n",
    "\n",
    "affinity_value = float(0.1)\n",
    "\n",
    "##### May want to change these variables #####\n",
    "# 157 is Histadine, 89 is Tyrosine, 211 is Phe\n",
    "# Note: the distance array starts at 0, so amino acids numbers from chimerax will be +1\n",
    "\n",
    "binding_site_residue1 = int(157)\n",
    "binding_site_residue2 = None  # You can set this to None if you don't want to filter by a second residue\n",
    "binding_site_residue3 = None  # You can set this to None if you don't want to filter by a third residue\n",
    "distance_threshold = float(15.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef6d296a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on folder: boltz_results_391/predictions/391\n",
      "Processing folder: boltz_results_391/predictions/391\n",
      "Affinity data matched for 1 models\n",
      "Predictions folder does not exist: boltz_results_combined.csv/predictions/combined.csv\n",
      "Predictions folder does not exist: boltz_results_confidence_filtered.csv/predictions/confidence\n",
      "working on folder: boltz_results_4839/predictions/4839\n",
      "Processing folder: boltz_results_4839/predictions/4839\n",
      "Affinity data matched for 1 models\n",
      "working on folder: boltz_results_1945/predictions/1945\n",
      "Processing folder: boltz_results_1945/predictions/1945\n",
      "Affinity data matched for 1 models\n",
      "working on folder: boltz_results_4897/predictions/4897\n",
      "Processing folder: boltz_results_4897/predictions/4897\n",
      "Affinity data matched for 1 models\n",
      "Predictions folder does not exist: boltz_results_filtered.csv/predictions/filtered.csv\n",
      "working on folder: boltz_results_5789/predictions/5789\n",
      "Processing folder: boltz_results_5789/predictions/5789\n",
      "Affinity data matched for 1 models\n",
      "Combined results saved to 'boltz_results_combined.csv'\n",
      "Copied ./boltz_results_1945/predictions/1945/1945_model_0.pdb to confidence_filtered_models\n",
      "Copied ./boltz_results_4839/predictions/4839/4839_model_0.pdb to confidence_filtered_models\n",
      "Copied ./boltz_results_391/predictions/391/391_model_0.pdb to confidence_filtered_models\n",
      "Copied ./boltz_results_5789/predictions/5789/5789_model_0.pdb to confidence_filtered_models\n",
      "Copied ./boltz_results_4897/predictions/4897/4897_model_0.pdb to confidence_filtered_models\n",
      "Copied ./boltz_results_1945/predictions/1945/1945_model_0.pdb to affinity_filtered_models\n",
      "Copied ./boltz_results_4839/predictions/4839/4839_model_0.pdb to affinity_filtered_models\n",
      "Copied ./boltz_results_391/predictions/391/391_model_0.pdb to affinity_filtered_models\n",
      "Copied ./boltz_results_1945/predictions/1945/1945_model_0.pdb to combined_models\n",
      "Copied ./boltz_results_4839/predictions/4839/4839_model_0.pdb to combined_models\n",
      "Copied ./boltz_results_391/predictions/391/391_model_0.pdb to combined_models\n",
      "Copied ./boltz_results_5789/predictions/5789/5789_model_0.pdb to combined_models\n",
      "Copied ./boltz_results_4897/predictions/4897/4897_model_0.pdb to combined_models\n"
     ]
    }
   ],
   "source": [
    "# Parsing results and initial confidence filtering\n",
    "\n",
    "#print(f\"Found folders: {folder_list}\")  # Debugging statement\n",
    "\n",
    "for folder in folder_list:\n",
    "    if folder.startswith('boltz_results_'):\n",
    "        predictions_folder = os.path.join(folder, 'predictions/', folder.split('_')[2])\n",
    "        if not os.path.exists(predictions_folder):\n",
    "            print(f\"Predictions folder does not exist: {predictions_folder}\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"working on folder: {predictions_folder}\")\n",
    "        print(f\"Processing folder: {predictions_folder}\")  # Debugging statement\n",
    "        results_df = parse_boltz2_results(os.path.join('./', predictions_folder))\n",
    "        # For example, to save it as a CSV file:\n",
    "        results_df.to_csv(f\"{folder}_results.csv\", index=False)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Combine all the CSV files into a single DataFrame\n",
    "\n",
    "file_list = [f for f in os.listdir('./') if f.endswith('_results.csv')]\n",
    "\n",
    "combined_df = combine_csv_results(file_list)\n",
    "combined_df.to_csv('boltz_results_combined.csv', index=False)\n",
    "print(\"Combined results saved to 'boltz_results_combined.csv'\")  # Debugging statement\n",
    "\n",
    "# remove the temporary .csv files\n",
    "for file in file_list:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        #print(f\"Removed temporary file: {file}\")  # Debugging statement\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Filtering the DataFrame to include only rows with a confidence score greater than the specified value \n",
    "confidence_filtered_df = combined_df[combined_df['confidence_score'] > confidence_value]\n",
    "confidence_filtered_df.to_csv('boltz_results_confidence_filtered.csv', index=False)\n",
    "\n",
    "# Using the filtered DataFrame to copy the corresponding .pdb model files into a new directory\n",
    "confidence_filtered_dir = 'confidence_filtered_models'\n",
    "os.makedirs(confidence_filtered_dir, exist_ok=True)\n",
    "for index, row in confidence_filtered_df.iterrows():\n",
    "    model_path = row['model_path']\n",
    "    if os.path.exists(model_path):\n",
    "        # Copy the model file to the output directory\n",
    "        os.system(f\"cp {model_path} {confidence_filtered_dir}\")\n",
    "        print(f\"Copied {model_path} to {confidence_filtered_dir}\")\n",
    "    else:\n",
    "        print(f\"Model file does not exist: {model_path}\")  # Debugging statement\n",
    "\n",
    "affinity_filtered_df = combined_df[combined_df['affinity_pred_value'] > affinity_value]\n",
    "affinity_filtered_df.to_csv('boltz_results_affinity_filtered.csv', index=False)\n",
    "\n",
    "# Using the filtered DataFrame to copy the corresponding .pdb model files into a new directory\n",
    "affinity_filtered_dir = 'affinity_filtered_models'\n",
    "os.makedirs(affinity_filtered_dir, exist_ok=True)\n",
    "for index, row in affinity_filtered_df.iterrows():\n",
    "    model_path = row['model_path']\n",
    "    if os.path.exists(model_path):\n",
    "        # Copy the model file to the output directory\n",
    "        os.system(f\"cp {model_path} {affinity_filtered_dir}\")\n",
    "        print(f\"Copied {model_path} to {affinity_filtered_dir}\")\n",
    "    else:\n",
    "        print(f\"Model file does not exist: {model_path}\")  # Debugging statement\n",
    "\n",
    "# Copy all the .pdb files from the combined results to a new directory\n",
    "combined_output_dir = 'combined_models'\n",
    "os.makedirs(combined_output_dir, exist_ok=True)\n",
    "for file in combined_df['model_path'].unique():\n",
    "    if os.path.exists(file):\n",
    "        # Copy the model file to the output directory\n",
    "        os.system(f\"cp {file} {combined_output_dir}\")\n",
    "        print(f\"Copied {file} to {combined_output_dir}\")\n",
    "    else:\n",
    "        print(f\"File does not exist: {file}\")  # Debugging statement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31de5529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boltz2-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
