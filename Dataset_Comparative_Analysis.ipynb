{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae101876",
   "metadata": {},
   "source": [
    "# GPCRSARfari vs ChEMBL Dataset Comparative Analysis\n",
    "# GPCRSARfari vs ChEMBL 数据集比较分析\n",
    "\n",
    "本notebook对比分析两个数据集的以下维度 / This notebook compares the two datasets across the following dimensions:\n",
    "1. **Hit Count & Hit Rate** - 数据集整体覆盖度差异 / Overall dataset coverage differences\n",
    "2. **False Negative Rate/False Positive Rate (FNR/FPR)** - 识别性能差异 / Identification performance differences  \n",
    "3. **Chemical Space Distribution** - 多样性与分布差异 / Diversity and distribution differences\n",
    "4. **Scaffold Composition** - 结构骨架侧重点差异 / Structural scaffold focus differences\n",
    "5. **Known Target Distribution** - 原始注释差异 / Original annotation differences\n",
    "6. **Overlap Analysis** - 重叠vs互补性分析 / Overlap vs complementarity analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc5b313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries and Setup / 导入必要库和设置\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# Configure matplotlib for Chinese font support / 配置matplotlib支持中文字体\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Try to find available Chinese fonts / 尝试寻找可用的中文字体\n",
    "available_fonts = ['SimHei', 'Microsoft YaHei', 'SimSun', 'KaiTi', 'FangSong', 'DejaVu Sans', 'Arial Unicode MS', 'sans-serif']\n",
    "font_found = False\n",
    "\n",
    "for font_name in available_fonts:\n",
    "    try:\n",
    "        plt.rcParams['font.sans-serif'] = [font_name] + ['DejaVu Sans', 'sans-serif']\n",
    "        # Test if font works with Chinese characters / 测试字体是否支持中文字符\n",
    "        fig, ax = plt.subplots(figsize=(1, 1))\n",
    "        ax.text(0.5, 0.5, '测试', fontsize=10)\n",
    "        plt.close(fig)\n",
    "        print(f\"Using font: {font_name} for Chinese text support\")\n",
    "        font_found = True\n",
    "        break\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "if not font_found:\n",
    "    print(\"Warning: No Chinese font found, Chinese characters may display as squares\")\n",
    "    plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'sans-serif']\n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 正确显示负号\n",
    "\n",
    "# Set up plotting style / 设置绘图风格\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Dataset Comparative Analysis Setup\")\n",
    "print(\"Libraries imported successfully\")\n",
    "\n",
    "# Create main output directory structure / 创建主要输出目录结构\n",
    "main_output_dir = Path(\"Dataset_Comparative_Analysis\")\n",
    "main_output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Create task-specific subdirectories / 创建任务专用子目录\n",
    "task_names = {\n",
    "    'task1': '01_Hit_Count_Rate_Analysis',\n",
    "    'task2': '02_FNR_Analysis', \n",
    "    'task3': '03_Chemical_Space_Distribution_Analysis',\n",
    "    'task4': '04_Scaffold_Composition_Analysis',\n",
    "    'task5': '05_Target_Distribution_Analysis',\n",
    "    'task6': '06_Overlap_Analysis'\n",
    "}\n",
    "\n",
    "task_dirs = {}\n",
    "for task_key, task_name in task_names.items():\n",
    "    task_dir = main_output_dir / task_name\n",
    "    task_dir.mkdir(exist_ok=True)\n",
    "    task_dirs[task_key] = task_dir\n",
    "    print(f\"Created directory: {task_dir}\")\n",
    "\n",
    "print(f\"Output directory structure created: {main_output_dir}\")\n",
    "\n",
    "# Helper function to ensure Chinese text displays correctly / 辅助函数确保中文正确显示\n",
    "def setup_chinese_font():\n",
    "    \"\"\"Setup matplotlib to display Chinese characters correctly\"\"\"\n",
    "    # Additional font configuration for better Chinese support\n",
    "    mpl.font_manager.fontManager.addfont('C:/Windows/Fonts/simhei.ttf')  # Try to add SimHei if available\n",
    "    plt.rcParams['font.family'] = 'sans-serif'\n",
    "    \n",
    "def safe_chinese_plot(fig):\n",
    "    \"\"\"Ensure the figure can display Chinese characters\"\"\"\n",
    "    try:\n",
    "        # Test Chinese character rendering\n",
    "        for ax in fig.get_axes():\n",
    "            for text in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "                if hasattr(text, 'get_text') and '/' in text.get_text():\n",
    "                    # Split bilingual text if needed\n",
    "                    pass\n",
    "        return fig\n",
    "    except Exception as e:\n",
    "        print(f\"Font rendering warning: {e}\")\n",
    "        return fig\n",
    "\n",
    "# Set output directory for backward compatibility / 设置输出目录以保持向后兼容性\n",
    "output_dir = main_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f3a269",
   "metadata": {},
   "source": [
    "## Task 1: Hit Count & Hit Rate Analysis\n",
    "## 任务一：命中数/命中率分析\n",
    "\n",
    "**Analysis Objective** / **分析目标**: Compare dataset scale and hit molecule counts to evaluate which dataset has stronger \"hit capability\" for 5HT2A receptor / 比较两个数据集的规模和命中分子数量，评估哪个数据集对5HT2A受体的\"命中能力\"更强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d691f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Hit Count and Hit Rate Analysis\n",
    "print(\"=\" * 60)\n",
    "print(\"Task 1: Hit Count and Hit Rate Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load datasets / 读取数据集\n",
    "gpcrsarfari_data = pd.read_csv(r\"c:\\000000000\\5HT2A\\Final_Filtered_models_with_ChemBL.csv\")\n",
    "chembl_data = pd.read_csv(r\"c:\\000000000\\5HT2A_M3\\Final_Filtered_models_with_ChemBL.csv\")\n",
    "\n",
    "# Load total datasets from boltz_results_combined.csv for real hit rate calculation / 从boltz_results_combined.csv读取总数据量进行真实命中率计算\n",
    "gpcrsarfari_total = pd.read_csv(r\"c:\\000000000\\5HT2A\\boltz_results_combined.csv\")\n",
    "chembl_total = pd.read_csv(r\"c:\\000000000\\5HT2A_M3\\boltz_results_combined.csv\")\n",
    "\n",
    "print(\"Dataset Information:\")\n",
    "print(f\"  GPCRSARfari Filtered Dataset: {len(gpcrsarfari_data)} compounds\")\n",
    "print(f\"  ChEMBL Filtered Dataset: {len(chembl_data)} compounds\")\n",
    "print(f\"  GPCRSARfari Total Dataset: {len(gpcrsarfari_total)} compounds (from boltz_results_combined.csv)\")\n",
    "print(f\"  ChEMBL Total Dataset: {len(chembl_total)} compounds (from boltz_results_combined.csv)\")\n",
    "\n",
    "# Calculate hit counts and total counts / 计算命中数和总数\n",
    "hits_gpcrsarfari = len(gpcrsarfari_data)\n",
    "hits_chembl = len(chembl_data)\n",
    "total_gpcrsarfari = len(gpcrsarfari_total)  # Real total library size / 真实总库大小\n",
    "total_chembl = len(chembl_total)  # Real total library size / 真实总库大小\n",
    "\n",
    "# Calculate real hit rates / 计算真实命中率\n",
    "hit_rate_gpcrsarfari = (hits_gpcrsarfari / total_gpcrsarfari) * 100\n",
    "hit_rate_chembl = (hits_chembl / total_chembl) * 100\n",
    "\n",
    "print(f\"\\nReal Hit Analysis Results:\")\n",
    "print(f\"  GPCRSARfari:\")\n",
    "print(f\"    Hits: {hits_gpcrsarfari}\")\n",
    "print(f\"    Total Library: {total_gpcrsarfari}\")\n",
    "print(f\"    Hit Rate: {hit_rate_gpcrsarfari:.3f}%\")\n",
    "print(f\"  ChEMBL:\")\n",
    "print(f\"    Hits: {hits_chembl}\")\n",
    "print(f\"    Total Library: {total_chembl}\")\n",
    "print(f\"    Hit Rate: {hit_rate_chembl:.3f}%\")\n",
    "\n",
    "print(f\"\\nComparative Analysis:\")\n",
    "print(f\"  Hit Rate Ratio (GPCRSARfari/ChEMBL): {hit_rate_gpcrsarfari/hit_rate_chembl:.2f}\")\n",
    "print(f\"  GPCRSARfari is {hit_rate_gpcrsarfari/hit_rate_chembl:.1f}x more efficient in hit identification\")\n",
    "\n",
    "# Create visualizations / 创建可视化\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Hit count comparison / 命中计数对比\n",
    "datasets = ['GPCRSARfari', 'ChEMBL']\n",
    "hit_counts = [hits_gpcrsarfari, hits_chembl]\n",
    "colors = ['skyblue', 'lightcoral']\n",
    "\n",
    "bars1 = ax1.bar(datasets, hit_counts, color=colors, alpha=0.7)\n",
    "ax1.set_ylabel('Hit Count')\n",
    "ax1.set_title('Hit Count Comparison')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars / 在柱状图上添加数值标签\n",
    "for bar, count in zip(bars1, hit_counts):\n",
    "    height = bar.get_height()\n",
    "    ax1.annotate(f'{count}', xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Hit rate comparison / 命中率对比\n",
    "hit_rates = [hit_rate_gpcrsarfari, hit_rate_chembl]\n",
    "bars2 = ax2.bar(datasets, hit_rates, color=colors, alpha=0.7)\n",
    "ax2.set_ylabel('Hit Rate (%)')\n",
    "ax2.set_title('Hit Rate Comparison')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "for bar, rate in zip(bars2, hit_rates):\n",
    "    height = bar.get_height()\n",
    "    ax2.annotate(f'{rate:.3f}%', xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. Total library size vs hits / 总库大小 vs 命中数\n",
    "total_counts = [total_gpcrsarfari, total_chembl]\n",
    "width = 0.35\n",
    "x = np.arange(len(datasets))\n",
    "\n",
    "bars3 = ax3.bar(x - width/2, total_counts, width, label='Total Library', color='lightblue', alpha=0.7)\n",
    "bars4 = ax3.bar(x + width/2, hit_counts, width, label='Hits', color='orange', alpha=0.7)\n",
    "\n",
    "ax3.set_ylabel('Count')\n",
    "ax3.set_title('Library Size vs Hits')\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(datasets)\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (total, hits) in enumerate(zip(total_counts, hit_counts)):\n",
    "    ax3.annotate(f'{total}', xy=(i - width/2, total), xytext=(0, 3), \n",
    "                textcoords=\"offset points\", ha='center', va='bottom', fontsize=9)\n",
    "    ax3.annotate(f'{hits}', xy=(i + width/2, hits), xytext=(0, 3), \n",
    "                textcoords=\"offset points\", ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 4. Efficiency ratio (hits per 1000 compounds) / 效率比（每1000个化合物的命中数）\n",
    "efficiency_gpcrsarfari = (hits_gpcrsarfari / total_gpcrsarfari) * 1000\n",
    "efficiency_chembl = (hits_chembl / total_chembl) * 1000\n",
    "efficiencies = [efficiency_gpcrsarfari, efficiency_chembl]\n",
    "\n",
    "bars5 = ax4.bar(datasets, efficiencies, color=['lightgreen', 'lightsalmon'], alpha=0.7)\n",
    "ax4.set_ylabel('Hits per 1000 Compounds')\n",
    "ax4.set_title('Screening Efficiency')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "for bar, eff in zip(bars5, efficiencies):\n",
    "    height = bar.get_height()\n",
    "    ax4.annotate(f'{eff:.1f}', xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save to task-specific directory / 保存到任务专用目录\n",
    "task1_dir = task_dirs['task1']\n",
    "fig.savefig(task1_dir / 'hit_analysis_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save statistics to CSV / 保存统计数据到CSV\n",
    "stats_data = {\n",
    "    'Dataset': ['GPCRSARfari', 'ChEMBL'],\n",
    "    'Hit_Count': [hits_gpcrsarfari, hits_chembl],\n",
    "    'Total_Library_Size': [total_gpcrsarfari, total_chembl],\n",
    "    'Hit_Rate_Percent': [hit_rate_gpcrsarfari, hit_rate_chembl],\n",
    "    'Hits_per_1000': [efficiency_gpcrsarfari, efficiency_chembl]\n",
    "}\n",
    "\n",
    "stats_df = pd.DataFrame(stats_data)\n",
    "stats_df.to_csv(task1_dir / 'hit_analysis_summary.csv', index=False)\n",
    "\n",
    "print(f\"\\nFiles saved to: {task1_dir}\")\n",
    "print(\"   - hit_analysis_comparison.png\")\n",
    "print(\"   - hit_analysis_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e09d8b5",
   "metadata": {},
   "source": [
    "## Task 2: False Negative Rate/False Positive Rate (FNR/FPR) Analysis\n",
    "## 任务二：假阴性率/假阳性率 (FNR/FPR) 分析\n",
    "\n",
    "**Analysis Objective** / **分析目标**: Compare false negative rates between datasets to evaluate which dataset is more prone to missing true 5HT2A active compounds / 比较两个数据集的假阴性率，评估哪个数据集更容易漏掉真正的5HT2A活性化合物"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b5854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: False Negative Rate (FNR) Comparison\n",
    "print(\"=\" * 60)\n",
    "print(\"Task 2: False Negative Rate/False Positive Rate (FNR/FPR) Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load FNR data / 读取FNR数据\n",
    "fnr_gpcrsarfari = pd.read_csv(r\"c:\\000000000\\5HT2A\\False_Negative\\FNR%.csv\")\n",
    "fnr_chembl = pd.read_csv(r\"c:\\000000000\\5HT2A_M3\\False_Negative\\FNR%.csv\")\n",
    "\n",
    "print(\"False Negative Rate (FNR) Statistics:\")\n",
    "print(\"GPCRSARfari Dataset:\")\n",
    "print(f\"  Known Actives: {fnr_gpcrsarfari.iloc[0]['Known Actives']}\")\n",
    "print(f\"  Retrieved Actives: {fnr_gpcrsarfari.iloc[0]['Retrieved Actives']}\")\n",
    "print(f\"  Missed Actives (FN): {fnr_gpcrsarfari.iloc[0]['Missed Actives (FN)']}\")\n",
    "print(f\"  False Negative Rate: {fnr_gpcrsarfari.iloc[0]['False Negative Rate (FNR)']}\")\n",
    "\n",
    "print(\"\\nChEMBL Dataset:\")\n",
    "print(f\"  Known Actives: {fnr_chembl.iloc[0]['Known Actives']}\")\n",
    "print(f\"  Retrieved Actives: {fnr_chembl.iloc[0]['Retrieved Actives']}\")\n",
    "print(f\"  Missed Actives (FN): {fnr_chembl.iloc[0]['Missed Actives (FN)']}\")\n",
    "print(f\"  False Negative Rate: {fnr_chembl.iloc[0]['False Negative Rate (FNR)']}\")\n",
    "\n",
    "# Extract numerical values for visualization / 提取数值用于可视化\n",
    "fnr_gpcrsarfari_val = float(fnr_gpcrsarfari.iloc[0]['False Negative Rate (FNR)'].replace('%', ''))\n",
    "fnr_chembl_val = float(fnr_chembl.iloc[0]['False Negative Rate (FNR)'].replace('%', ''))\n",
    "\n",
    "known_gpcrsarfari = fnr_gpcrsarfari.iloc[0]['Known Actives']\n",
    "known_chembl = fnr_chembl.iloc[0]['Known Actives']\n",
    "retrieved_gpcrsarfari = fnr_gpcrsarfari.iloc[0]['Retrieved Actives']\n",
    "retrieved_chembl = fnr_chembl.iloc[0]['Retrieved Actives']\n",
    "missed_gpcrsarfari = fnr_gpcrsarfari.iloc[0]['Missed Actives (FN)']\n",
    "missed_chembl = fnr_chembl.iloc[0]['Missed Actives (FN)']\n",
    "\n",
    "# Create visualization / 创建可视化\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. FNR comparison / FNR对比\n",
    "datasets = ['GPCRSARfari', 'ChEMBL']\n",
    "fnr_values = [fnr_gpcrsarfari_val, fnr_chembl_val]\n",
    "colors = ['red' if x > 70 else 'orange' if x > 50 else 'green' for x in fnr_values]\n",
    "\n",
    "bars1 = ax1.bar(datasets, fnr_values, color=colors, alpha=0.7)\n",
    "ax1.set_ylabel('False Negative Rate (%)')\n",
    "ax1.set_title('False Negative Rate (FNR) Comparison')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 100)\n",
    "\n",
    "for bar, val in zip(bars1, fnr_values):\n",
    "    ax1.annotate(f'{val:.1f}%', xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 2. Sensitivity comparison (1-FNR) / 敏感性对比（1-FNR）\n",
    "sensitivity_values = [100 - x for x in fnr_values]\n",
    "bars2 = ax2.bar(datasets, sensitivity_values, color=['lightgreen', 'lightblue'], alpha=0.7)\n",
    "ax2.set_ylabel('Sensitivity (%)')\n",
    "ax2.set_title('Sensitivity (Sensitivity = 1 - FNR) Comparison')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(0, 100)\n",
    "\n",
    "for bar, val in zip(bars2, sensitivity_values):\n",
    "    ax2.annotate(f'{val:.1f}%', xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 3. Stacked bar chart: Retrieved vs Missed / 堆积柱状图：检索到 vs 漏掉\n",
    "retrieved_data = [retrieved_gpcrsarfari, retrieved_chembl]\n",
    "missed_data = [missed_gpcrsarfari, missed_chembl]\n",
    "\n",
    "bars3 = ax3.bar(datasets, retrieved_data, label='Retrieved', color='lightgreen', alpha=0.8)\n",
    "bars4 = ax3.bar(datasets, missed_data, bottom=retrieved_data, label='Missed', color='lightcoral', alpha=0.8)\n",
    "\n",
    "ax3.set_ylabel('Number of Compounds')\n",
    "ax3.set_title('Known Active Compound Retrieval Performance')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value annotations / 添加数值标注\n",
    "for i, (ret, miss) in enumerate(zip(retrieved_data, missed_data)):\n",
    "    ax3.annotate(f'{ret}', xy=(i, ret/2), ha='center', va='center', fontweight='bold')\n",
    "    ax3.annotate(f'{miss}', xy=(i, ret + miss/2), ha='center', va='center', fontweight='bold')\n",
    "\n",
    "# 4. Pie charts comparison / 饼图对比\n",
    "pie_data_gpcrsarfari = [retrieved_gpcrsarfari, missed_gpcrsarfari]\n",
    "pie_data_chembl = [retrieved_chembl, missed_chembl]\n",
    "labels = ['Retrieved', 'Missed']\n",
    "colors_pie = ['lightgreen', 'lightcoral']\n",
    "\n",
    "# Create subplot for pie charts\n",
    "ax4.axis('off')\n",
    "fig2, (ax_pie1, ax_pie2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax_pie1.pie(pie_data_gpcrsarfari, labels=labels, autopct='%1.1f%%', \n",
    "            startangle=90, colors=colors_pie)\n",
    "ax_pie1.set_title(f'GPCRSARfari (FNR: {fnr_gpcrsarfari_val:.1f}%)')\n",
    "\n",
    "ax_pie2.pie(pie_data_chembl, labels=labels, autopct='%1.1f%%', \n",
    "            startangle=90, colors=colors_pie)\n",
    "ax_pie2.set_title(f'ChEMBL (FNR: {fnr_chembl_val:.1f}%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save to task-specific directory / 保存到任务专用目录\n",
    "task2_dir = task_dirs['task2']\n",
    "fig.savefig(task2_dir / 'fnr_comparison_main.png', dpi=300, bbox_inches='tight')\n",
    "fig2.savefig(task2_dir / 'fnr_comparison_pies.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save FNR data to CSV / 保存FNR数据到CSV\n",
    "fnr_summary = {\n",
    "    'Dataset': ['GPCRSARfari', 'ChEMBL'],\n",
    "    'Known_Actives': [known_gpcrsarfari, known_chembl],\n",
    "    'Retrieved_Actives': [retrieved_gpcrsarfari, retrieved_chembl],\n",
    "    'Missed_Actives': [missed_gpcrsarfari, missed_chembl],\n",
    "    'FNR_Percent': [fnr_gpcrsarfari_val, fnr_chembl_val],\n",
    "    'Sensitivity_Percent': [100-fnr_gpcrsarfari_val, 100-fnr_chembl_val]\n",
    "}\n",
    "fnr_df = pd.DataFrame(fnr_summary)\n",
    "fnr_df.to_csv(task2_dir / 'fnr_analysis_summary.csv', index=False)\n",
    "\n",
    "print(f\"\\nFiles saved to: {task2_dir}\")\n",
    "print(\"   - fnr_comparison_main.png\")\n",
    "print(\"   - fnr_comparison_pies.png\") \n",
    "print(\"   - fnr_analysis_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1336cd6b",
   "metadata": {},
   "source": [
    "## Task 3: Chemical Space Distribution Analysis\n",
    "## 任务三：化学空间分布分析\n",
    "\n",
    "**Analysis Objective** / **分析目标**: Compare chemical diversity and distribution differences of hit compounds through t-SNE dimensionality reduction visualization / 通过t-SNE降维可视化，对比两个数据集命中化合物的化学多样性和分布差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb95ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Chemical Space Distribution Analysis\n",
    "print(\"=\" * 60)\n",
    "print(\"Task 3: Chemical Space Distribution Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load molecular data / 读取分子数据\n",
    "gpcrsarfari_data = pd.read_csv(r\"c:\\000000000\\5HT2A\\Final_Filtered_models_with_ChemBL.csv\")\n",
    "chembl_data = pd.read_csv(r\"c:\\000000000\\5HT2A_M3\\Final_Filtered_models_with_ChemBL.csv\")\n",
    "\n",
    "print(f\"Dataset Sizes:\")\n",
    "print(f\"  GPCRSARfari: {len(gpcrsarfari_data)} compounds\")\n",
    "print(f\"  ChEMBL: {len(chembl_data)} compounds\")\n",
    "\n",
    "# Load t-SNE coordinates for chemical space analysis / 读取t-SNE坐标进行化学空间分析\n",
    "tsne_gpcrsarfari = pd.read_csv(r\"c:\\000000000\\5HT2A\\TargetAnalysis\\02_ChemicalSimilarity\\tsne_coordinates.csv\")\n",
    "tsne_chembl = pd.read_csv(r\"c:\\000000000\\5HT2A_M3\\TargetAnalysis\\02_ChemicalSimilarity\\tsne_coordinates.csv\")\n",
    "\n",
    "print(f\"\\nt-SNE Data Structure:\")\n",
    "print(f\"  GPCRSARfari columns: {list(tsne_gpcrsarfari.columns)}\")\n",
    "print(f\"  ChEMBL columns: {list(tsne_chembl.columns)}\")\n",
    "\n",
    "# Calculate chemical space metrics / 计算化学空间度量\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def calculate_chemical_space_metrics(tsne_coords):\n",
    "    \"\"\"Calculate chemical space coverage metrics / 计算化学空间覆盖度量\"\"\"\n",
    "    # Check column names and use appropriate ones / 检查列名并使用适当的列名\n",
    "    if 'x' in tsne_coords.columns and 'y' in tsne_coords.columns:\n",
    "        x_col, y_col = 'x', 'y'\n",
    "    elif 'tsne_1' in tsne_coords.columns and 'tsne_2' in tsne_coords.columns:\n",
    "        x_col, y_col = 'tsne_1', 'tsne_2'\n",
    "    else:\n",
    "        # Use first two numeric columns / 使用前两个数值列\n",
    "        numeric_cols = tsne_coords.select_dtypes(include=[np.number]).columns\n",
    "        if len(numeric_cols) >= 2:\n",
    "            x_col, y_col = numeric_cols[0], numeric_cols[1]\n",
    "        else:\n",
    "            return 0, 0, None, None\n",
    "    \n",
    "    # Convex hull area (chemical space coverage) / 凸包面积（化学空间覆盖度）\n",
    "    try:\n",
    "        hull = ConvexHull(tsne_coords[[x_col, y_col]].values)\n",
    "        area = hull.volume  # In 2D, volume is area\n",
    "    except:\n",
    "        area = 0\n",
    "    \n",
    "    # Density distribution (entropy of discretized space) / 密度分布（离散化空间的熵）\n",
    "    x_bins = np.histogram_bin_edges(tsne_coords[x_col], bins=20)\n",
    "    y_bins = np.histogram_bin_edges(tsne_coords[y_col], bins=20)\n",
    "    hist, _, _ = np.histogram2d(tsne_coords[x_col], tsne_coords[y_col], bins=[x_bins, y_bins])\n",
    "    \n",
    "    # Normalize and calculate entropy / 归一化并计算熵\n",
    "    hist_norm = hist.flatten() / hist.sum()\n",
    "    hist_norm = hist_norm[hist_norm > 0]  # Remove zeros for entropy calculation\n",
    "    space_entropy = entropy(hist_norm)\n",
    "    \n",
    "    return area, space_entropy, x_col, y_col\n",
    "\n",
    "area_gpcrsarfari, entropy_gpcrsarfari, x_col_gpcr, y_col_gpcr = calculate_chemical_space_metrics(tsne_gpcrsarfari)\n",
    "area_chembl, entropy_chembl, x_col_chembl, y_col_chembl = calculate_chemical_space_metrics(tsne_chembl)\n",
    "\n",
    "print(f\"\\nChemical Space Metrics:\")\n",
    "print(f\"  GPCRSARfari:\")\n",
    "print(f\"    Coverage Area: {area_gpcrsarfari:.2f}\")\n",
    "print(f\"    Distribution Entropy: {entropy_gpcrsarfari:.3f}\")\n",
    "print(f\"    Using columns: {x_col_gpcr}, {y_col_gpcr}\")\n",
    "print(f\"  ChEMBL:\")\n",
    "print(f\"    Coverage Area: {area_chembl:.2f}\")\n",
    "print(f\"    Distribution Entropy: {entropy_chembl:.3f}\")\n",
    "print(f\"    Using columns: {x_col_chembl}, {y_col_chembl}\")\n",
    "\n",
    "# Create comprehensive visualization / 创建综合可视化\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. t-SNE scatter plots / t-SNE散点图\n",
    "scatter1 = ax1.scatter(tsne_gpcrsarfari[x_col_gpcr], tsne_gpcrsarfari[y_col_gpcr], \n",
    "                       alpha=0.6, s=30, c='blue', label='GPCRSARfari')\n",
    "ax1.set_title('GPCRSARfari Chemical Space Distribution')\n",
    "ax1.set_xlabel(f'{x_col_gpcr}')\n",
    "ax1.set_ylabel(f'{y_col_gpcr}')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "scatter2 = ax2.scatter(tsne_chembl[x_col_chembl], tsne_chembl[y_col_chembl], \n",
    "                       alpha=0.6, s=30, c='red', label='ChEMBL')\n",
    "ax2.set_title('ChEMBL Chemical Space Distribution')\n",
    "ax2.set_xlabel(f'{x_col_chembl}')\n",
    "ax2.set_ylabel(f'{y_col_chembl}')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Coverage area comparison / 覆盖面积对比\n",
    "datasets = ['GPCRSARfari', 'ChEMBL']\n",
    "areas = [area_gpcrsarfari, area_chembl]\n",
    "bars3 = ax3.bar(datasets, areas, color=['skyblue', 'lightcoral'], alpha=0.7)\n",
    "ax3.set_ylabel('Chemical Space Coverage Area')\n",
    "ax3.set_title('Chemical Space Coverage Comparison')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "for bar, area in zip(bars3, areas):\n",
    "    ax3.annotate(f'{area:.1f}', xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 4. Distribution entropy comparison / 分布熵对比\n",
    "entropies = [entropy_gpcrsarfari, entropy_chembl]\n",
    "bars4 = ax4.bar(datasets, entropies, color=['lightgreen', 'lightsalmon'], alpha=0.7)\n",
    "ax4.set_ylabel('Distribution Entropy')\n",
    "ax4.set_title('Chemical Space Distribution Entropy')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "for bar, entropy_val in zip(bars4, entropies):\n",
    "    ax4.annotate(f'{entropy_val:.3f}', xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create overlay comparison / 创建叠加对比图\n",
    "fig2, ax5 = plt.subplots(1, 1, figsize=(12, 8))\n",
    "scatter_overlay1 = ax5.scatter(tsne_gpcrsarfari[x_col_gpcr], tsne_gpcrsarfari[y_col_gpcr], \n",
    "                              alpha=0.6, s=30, c='blue', label='GPCRSARfari')\n",
    "scatter_overlay2 = ax5.scatter(tsne_chembl[x_col_chembl], tsne_chembl[y_col_chembl], \n",
    "                              alpha=0.6, s=30, c='red', label='ChEMBL')\n",
    "ax5.set_title('Chemical Space Overlap Comparison')\n",
    "ax5.set_xlabel('t-SNE Dimension 1')\n",
    "ax5.set_ylabel('t-SNE Dimension 2')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# Create density heatmaps / 创建密度热力图\n",
    "fig3, (ax6, ax7) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# GPCRSARfari density heatmap / GPCRSARfari 密度热力图\n",
    "hist1, xedges1, yedges1 = np.histogram2d(tsne_gpcrsarfari[x_col_gpcr], tsne_gpcrsarfari[y_col_gpcr], bins=25)\n",
    "extent1 = [xedges1[0], xedges1[-1], yedges1[0], yedges1[-1]]\n",
    "im1 = ax6.imshow(hist1.T, origin='lower', extent=extent1, cmap='Blues', alpha=0.8)\n",
    "ax6.set_title('GPCRSARfari Density Distribution')\n",
    "ax6.set_xlabel(f'{x_col_gpcr}')\n",
    "ax6.set_ylabel(f'{y_col_gpcr}')\n",
    "plt.colorbar(im1, ax=ax6, label='Density')\n",
    "\n",
    "# ChEMBL density heatmap / ChEMBL 密度热力图\n",
    "hist2, xedges2, yedges2 = np.histogram2d(tsne_chembl[x_col_chembl], tsne_chembl[y_col_chembl], bins=25)\n",
    "extent2 = [xedges2[0], xedges2[-1], yedges2[0], yedges2[-1]]\n",
    "im2 = ax7.imshow(hist2.T, origin='lower', extent=extent2, cmap='Reds', alpha=0.8)\n",
    "ax7.set_title('ChEMBL Density Distribution')\n",
    "ax7.set_xlabel(f'{x_col_chembl}')\n",
    "ax7.set_ylabel(f'{y_col_chembl}')\n",
    "plt.colorbar(im2, ax=ax7, label='Density')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save to task-specific directory / 保存到任务专用目录\n",
    "task3_dir = task_dirs['task3']\n",
    "fig.savefig(task3_dir / 'chemical_space_metrics.png', dpi=300, bbox_inches='tight')\n",
    "fig2.savefig(task3_dir / 'chemical_space_overlay.png', dpi=300, bbox_inches='tight')\n",
    "fig3.savefig(task3_dir / 'chemical_space_density.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save chemical space analysis to CSV / 保存化学空间分析到CSV\n",
    "chemical_space_summary = {\n",
    "    'Dataset': ['GPCRSARfari', 'ChEMBL'],\n",
    "    'Number_of_Compounds': [len(gpcrsarfari_data), len(chembl_data)],\n",
    "    'Coverage_Area': [area_gpcrsarfari, area_chembl],\n",
    "    'Distribution_Entropy': [entropy_gpcrsarfari, entropy_chembl],\n",
    "    'X_Range': [tsne_gpcrsarfari[x_col_gpcr].max() - tsne_gpcrsarfari[x_col_gpcr].min(),\n",
    "                tsne_chembl[x_col_chembl].max() - tsne_chembl[x_col_chembl].min()],\n",
    "    'Y_Range': [tsne_gpcrsarfari[y_col_gpcr].max() - tsne_gpcrsarfari[y_col_gpcr].min(),\n",
    "                tsne_chembl[y_col_chembl].max() - tsne_chembl[y_col_chembl].min()]\n",
    "}\n",
    "chemical_space_df = pd.DataFrame(chemical_space_summary)\n",
    "chemical_space_df.to_csv(task3_dir / 'chemical_space_analysis_summary.csv', index=False)\n",
    "\n",
    "# Save t-SNE coordinates with dataset labels / 保存带数据集标签的t-SNE坐标\n",
    "tsne_gpcrsarfari_labeled = tsne_gpcrsarfari.copy()\n",
    "tsne_gpcrsarfari_labeled['Dataset'] = 'GPCRSARfari'\n",
    "tsne_chembl_labeled = tsne_chembl.copy()\n",
    "tsne_chembl_labeled['Dataset'] = 'ChEMBL'\n",
    "\n",
    "combined_tsne = pd.concat([tsne_gpcrsarfari_labeled, tsne_chembl_labeled], ignore_index=True)\n",
    "combined_tsne.to_csv(task3_dir / 'combined_tsne_coordinates.csv', index=False)\n",
    "\n",
    "print(f\"\\nFiles saved to: {task3_dir}\")\n",
    "print(\"   - chemical_space_metrics.png\")\n",
    "print(\"   - chemical_space_overlay.png\")\n",
    "print(\"   - chemical_space_density.png\")\n",
    "print(\"   - chemical_space_analysis_summary.csv\")\n",
    "print(\"   - combined_tsne_coordinates.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e97109",
   "metadata": {},
   "source": [
    "## Task 4: Scaffold Composition Analysis\n",
    "## 任务四：骨架组成分析\n",
    "\n",
    "**Analysis Objective** / **分析目标**: Extract Murcko scaffolds to analyze focus and frequency differences at the structural scaffold level between datasets / 提取Murcko scaffold，分析两数据集在结构骨架层面的重点和频率差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744110aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Molecular Scaffold Composition Analysis\n",
    "print(\"=\" * 60)\n",
    "print(\"Task 4: Molecular Scaffold Composition Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Import RDKit for scaffold analysis / 导入RDKit进行骨架分析\n",
    "try:\n",
    "    from rdkit import Chem\n",
    "    from rdkit.Chem import rdMolDescriptors\n",
    "    from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "    print(\"RDKit imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"RDKit not available. Installing via conda...\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"conda\", \"install\", \"-c\", \"rdkit\", \"rdkit\", \"-y\"])\n",
    "    from rdkit import Chem\n",
    "    from rdkit.Chem import rdMolDescriptors\n",
    "    from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "\n",
    "def get_murcko_scaffold(smiles):\n",
    "    \"\"\"Extract Murcko scaffold from SMILES / 从SMILES提取Murcko骨架\"\"\"\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is not None:\n",
    "            scaffold = MurckoScaffold.GetScaffoldForMol(mol)\n",
    "            return Chem.MolToSmiles(scaffold)\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def analyze_scaffold_diversity(smiles_list, dataset_name):\n",
    "    \"\"\"Analyze scaffold diversity for a dataset / 分析数据集的骨架多样性\"\"\"\n",
    "    scaffolds = []\n",
    "    valid_smiles = 0\n",
    "    \n",
    "    print(f\"Processing {len(smiles_list)} SMILES for {dataset_name}...\")\n",
    "    \n",
    "    for i, smiles in enumerate(smiles_list):\n",
    "        if pd.isna(smiles):\n",
    "            continue\n",
    "            \n",
    "        scaffold = get_murcko_scaffold(smiles)\n",
    "        if scaffold:\n",
    "            scaffolds.append(scaffold)\n",
    "            valid_smiles += 1\n",
    "            \n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"  Processed {i+1}/{len(smiles_list)} molecules...\")\n",
    "    \n",
    "    # Calculate diversity metrics / 计算多样性度量\n",
    "    unique_scaffolds = list(set(scaffolds))\n",
    "    scaffold_counts = pd.Series(scaffolds).value_counts()\n",
    "    \n",
    "    # Shannon diversity / 香农多样性\n",
    "    from scipy.stats import entropy\n",
    "    shannon_diversity = entropy(scaffold_counts.values, base=2)\n",
    "    \n",
    "    # Simpson diversity / 辛普森多样性\n",
    "    n = len(scaffolds)\n",
    "    simpson_diversity = 1 - sum((ni/n)**2 for ni in scaffold_counts.values)\n",
    "    \n",
    "    results = {\n",
    "        'dataset_name': dataset_name,\n",
    "        'total_molecules': len(smiles_list),\n",
    "        'valid_molecules': valid_smiles,\n",
    "        'total_scaffolds': len(scaffolds),\n",
    "        'unique_scaffolds': len(unique_scaffolds),\n",
    "        'diversity_ratio': len(unique_scaffolds) / len(scaffolds) if scaffolds else 0,\n",
    "        'shannon_diversity': shannon_diversity,\n",
    "        'simpson_diversity': simpson_diversity,\n",
    "        'scaffold_counts': scaffold_counts,\n",
    "        'top_scaffolds': scaffold_counts.head(10)\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Load data and analyze scaffolds / 读取数据并分析骨架\n",
    "# Note: 5HT2A dataset represents GPCRSARfari-like data, 5HT2A_M3 represents ChEMBL-like data\n",
    "gpcrsarfari_data = pd.read_csv(r\"c:\\000000000\\5HT2A\\Final_Filtered_models_with_ChemBL.csv\")\n",
    "chembl_data = pd.read_csv(r\"c:\\000000000\\5HT2A_M3\\Final_Filtered_models_with_ChemBL.csv\")\n",
    "\n",
    "print(f\"GPCRSARfari dataset size: {len(gpcrsarfari_data)}\")\n",
    "print(f\"ChEMBL dataset size: {len(chembl_data)}\")\n",
    "\n",
    "# Extract SMILES columns / 提取SMILES列\n",
    "smiles_col = 'smiles'  # Correct column name / 正确的列名\n",
    "print(f\"Using SMILES column: {smiles_col}\")\n",
    "\n",
    "# Check if SMILES column exists / 检查SMILES列是否存在\n",
    "if smiles_col not in gpcrsarfari_data.columns:\n",
    "    print(f\"Available columns in GPCRSARfari data: {list(gpcrsarfari_data.columns)}\")\n",
    "if smiles_col not in chembl_data.columns:\n",
    "    print(f\"Available columns in ChEMBL data: {list(chembl_data.columns)}\")\n",
    "\n",
    "# Use actual SMILES data instead of synthetic data / 使用实际SMILES数据而不是合成数据\n",
    "gpcrsarfari_sample = gpcrsarfari_data\n",
    "chembl_sample = chembl_data\n",
    "\n",
    "# Extract actual SMILES for analysis / 提取实际SMILES进行分析\n",
    "gpcrsarfari_smiles = gpcrsarfari_sample[smiles_col].dropna().tolist()\n",
    "chembl_smiles = chembl_sample[smiles_col].dropna().tolist()\n",
    "\n",
    "print(f\"GPCRSARfari valid SMILES: {len(gpcrsarfari_smiles)}\")\n",
    "print(f\"ChEMBL valid SMILES: {len(chembl_smiles)}\")\n",
    "\n",
    "# Analyze scaffold diversity using real SMILES data / 使用真实SMILES数据分析骨架多样性\n",
    "gpcrsarfari_results = analyze_scaffold_diversity(gpcrsarfari_smiles, 'GPCRSARfari (5HT2A)')\n",
    "chembl_results = analyze_scaffold_diversity(chembl_smiles, 'ChEMBL (5HT2A_M3)')\n",
    "\n",
    "print(f\"\\nScaffold Diversity Analysis Results:\")\n",
    "print(f\"GPCRSARfari Dataset:\")\n",
    "print(f\"  Total Scaffolds: {gpcrsarfari_results['total_scaffolds']}\")\n",
    "print(f\"  Unique Scaffolds: {gpcrsarfari_results['unique_scaffolds']}\")\n",
    "print(f\"  Diversity Ratio: {gpcrsarfari_results['diversity_ratio']:.3f}\")\n",
    "print(f\"  Shannon Diversity: {gpcrsarfari_results['shannon_diversity']:.3f}\")\n",
    "print(f\"  Simpson Diversity: {gpcrsarfari_results['simpson_diversity']:.3f}\")\n",
    "\n",
    "print(f\"\\nChEMBL Dataset:\")\n",
    "print(f\"  Total Scaffolds: {chembl_results['total_scaffolds']}\")\n",
    "print(f\"  Unique Scaffolds: {chembl_results['unique_scaffolds']}\")\n",
    "print(f\"  Diversity Ratio: {chembl_results['diversity_ratio']:.3f}\")\n",
    "print(f\"  Shannon Diversity: {chembl_results['shannon_diversity']:.3f}\")\n",
    "print(f\"  Simpson Diversity: {chembl_results['simpson_diversity']:.3f}\")\n",
    "\n",
    "# Create comprehensive visualization / 创建综合可视化\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Diversity metrics comparison / 多样性度量对比\n",
    "datasets = ['GPCRSARfari', 'ChEMBL']\n",
    "diversity_ratios = [gpcrsarfari_results['diversity_ratio'], chembl_results['diversity_ratio']]\n",
    "shannon_divs = [gpcrsarfari_results['shannon_diversity'], chembl_results['shannon_diversity']]\n",
    "simpson_divs = [gpcrsarfari_results['simpson_diversity'], chembl_results['simpson_diversity']]\n",
    "\n",
    "x = np.arange(len(datasets))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax1.bar(x - width, diversity_ratios, width, label='Diversity Ratio', alpha=0.7)\n",
    "bars2 = ax1.bar(x, shannon_divs, width, label='Shannon Diversity', alpha=0.7)\n",
    "bars3 = ax1.bar(x + width, simpson_divs, width, label='Simpson Diversity', alpha=0.7)\n",
    "\n",
    "ax1.set_ylabel('Diversity Score')\n",
    "ax1.set_title('Scaffold Diversity Metrics Comparison')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(datasets)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Unique vs Total scaffolds / 独特 vs 总骨架数\n",
    "total_scaffolds = [gpcrsarfari_results['total_scaffolds'], chembl_results['total_scaffolds']]\n",
    "unique_scaffolds = [gpcrsarfari_results['unique_scaffolds'], chembl_results['unique_scaffolds']]\n",
    "\n",
    "bars4 = ax2.bar(x - width/2, total_scaffolds, width, label='Total Scaffolds', alpha=0.7, color='lightblue')\n",
    "bars5 = ax2.bar(x + width/2, unique_scaffolds, width, label='Unique Scaffolds', alpha=0.7, color='lightcoral')\n",
    "\n",
    "ax2.set_ylabel('Number of Scaffolds')\n",
    "ax2.set_title('Total vs Unique Scaffolds')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(datasets)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value annotations / 添加数值标注\n",
    "for i, (total, unique) in enumerate(zip(total_scaffolds, unique_scaffolds)):\n",
    "    ax2.annotate(f'{total}', xy=(i - width/2, total), xytext=(0, 3), \n",
    "                textcoords=\"offset points\", ha='center', va='bottom', fontweight='bold')\n",
    "    ax2.annotate(f'{unique}', xy=(i + width/2, unique), xytext=(0, 3), \n",
    "                textcoords=\"offset points\", ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. Top scaffolds frequency for GPCRSARfari / GPCRSARfari前几名骨架频率\n",
    "top_gpcrsarfari = gpcrsarfari_results['top_scaffolds']\n",
    "ax3.bar(range(len(top_gpcrsarfari)), top_gpcrsarfari.values, alpha=0.7, color='skyblue')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.set_title('Top 10 Scaffold Frequencies - GPCRSARfari')\n",
    "ax3.set_xticks(range(len(top_gpcrsarfari)))\n",
    "ax3.set_xticklabels([f'S{i+1}' for i in range(len(top_gpcrsarfari))], rotation=45)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Top scaffolds frequency for ChEMBL / ChEMBL前几名骨架频率\n",
    "top_chembl = chembl_results['top_scaffolds']\n",
    "ax4.bar(range(len(top_chembl)), top_chembl.values, alpha=0.7, color='lightcoral')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.set_title('Top 10 Scaffold Frequencies - ChEMBL')\n",
    "ax4.set_xticks(range(len(top_chembl)))\n",
    "ax4.set_xticklabels([f'S{i+1}' for i in range(len(top_chembl))], rotation=45)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create scaffold overlap analysis / 创建骨架重叠分析\n",
    "fig2, (ax5, ax6) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Venn diagram data / 维恩图数据\n",
    "gpcrsarfari_set = set(gpcrsarfari_results['scaffold_counts'].index)\n",
    "chembl_set = set(chembl_results['scaffold_counts'].index)\n",
    "overlap = len(gpcrsarfari_set.intersection(chembl_set))\n",
    "gpcrsarfari_only = len(gpcrsarfari_set - chembl_set)\n",
    "chembl_only = len(chembl_set - gpcrsarfari_set)\n",
    "\n",
    "# Manual Venn diagram representation\n",
    "venn_data = [gpcrsarfari_only, overlap, chembl_only]\n",
    "venn_labels = ['GPCRSARfari\\nOnly', 'Shared', 'ChEMBL\\nOnly']\n",
    "colors_venn = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "\n",
    "ax5.bar(venn_labels, venn_data, color=colors_venn, alpha=0.7)\n",
    "ax5.set_ylabel('Number of Unique Scaffolds')\n",
    "ax5.set_title('Scaffold Overlap Analysis')\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "for i, val in enumerate(venn_data):\n",
    "    ax5.annotate(f'{val}', xy=(i, val), xytext=(0, 3), \n",
    "                textcoords=\"offset points\", ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Jaccard similarity / Jaccard相似性\n",
    "jaccard_similarity = overlap / len(gpcrsarfari_set.union(chembl_set))\n",
    "ax6.bar(['Jaccard\\nSimilarity'], [jaccard_similarity], color='gold', alpha=0.7, width=0.5)\n",
    "ax6.set_ylabel('Similarity Score')\n",
    "ax6.set_title('Scaffold Jaccard Similarity')\n",
    "ax6.set_ylim(0, 1)\n",
    "ax6.grid(True, alpha=0.3)\n",
    "ax6.annotate(f'{jaccard_similarity:.3f}', xy=(0, jaccard_similarity), xytext=(0, 3), \n",
    "            textcoords=\"offset points\", ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save to task-specific directory / 保存到任务专用目录\n",
    "task4_dir = task_dirs['task4']\n",
    "fig.savefig(task4_dir / 'scaffold_diversity_analysis.png', dpi=300, bbox_inches='tight')\n",
    "fig2.savefig(task4_dir / 'scaffold_overlap_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save scaffold analysis to CSV / 保存骨架分析到CSV\n",
    "scaffold_summary = {\n",
    "    'Dataset': ['GPCRSARfari', 'ChEMBL'],\n",
    "    'Total_Scaffolds': [gpcrsarfari_results['total_scaffolds'], chembl_results['total_scaffolds']],\n",
    "    'Unique_Scaffolds': [gpcrsarfari_results['unique_scaffolds'], chembl_results['unique_scaffolds']],\n",
    "    'Diversity_Ratio': [gpcrsarfari_results['diversity_ratio'], chembl_results['diversity_ratio']],\n",
    "    'Shannon_Diversity': [gpcrsarfari_results['shannon_diversity'], chembl_results['shannon_diversity']],\n",
    "    'Simpson_Diversity': [gpcrsarfari_results['simpson_diversity'], chembl_results['simpson_diversity']]\n",
    "}\n",
    "scaffold_df = pd.DataFrame(scaffold_summary)\n",
    "scaffold_df.to_csv(task4_dir / 'scaffold_diversity_summary.csv', index=False)\n",
    "\n",
    "# Save overlap analysis / 保存重叠分析\n",
    "overlap_summary = {\n",
    "    'Metric': ['GPCRSARfari_Only', 'Shared_Scaffolds', 'ChEMBL_Only', 'Jaccard_Similarity'],\n",
    "    'Value': [gpcrsarfari_only, overlap, chembl_only, jaccard_similarity]\n",
    "}\n",
    "overlap_df = pd.DataFrame(overlap_summary)\n",
    "overlap_df.to_csv(task4_dir / 'scaffold_overlap_summary.csv', index=False)\n",
    "\n",
    "# Save top scaffolds / 保存顶级骨架\n",
    "gpcrsarfari_results['top_scaffolds'].to_csv(task4_dir / 'gpcrsarfari_top_scaffolds.csv', header=['Frequency'])\n",
    "chembl_results['top_scaffolds'].to_csv(task4_dir / 'chembl_top_scaffolds.csv', header=['Frequency'])\n",
    "\n",
    "print(f\"\\nFiles saved to: {task4_dir}\")\n",
    "\n",
    "print(\"   - scaffold_diversity_analysis.png\")\n",
    "print(\"   - scaffold_overlap_analysis.png\")\n",
    "print(\"   - scaffold_diversity_summary.csv\")\n",
    "print(\"   - scaffold_overlap_summary.csv\")\n",
    "print(\"   - gpcrsarfari_top_scaffolds.csv\")\n",
    "print(\"   - chembl_top_scaffolds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f0fa50",
   "metadata": {},
   "source": [
    "## Task 5: Known Target Distribution Analysis\n",
    "## 任务五：已知靶点分布分析\n",
    "\n",
    "**Analysis Objective** / **分析目标**: Analyze original ChEMBL annotation target distribution of hit compounds to determine which dataset is more biased toward cross-target compounds / 统计两数据集命中化合物的原始ChEMBL注释靶点分布，分析哪个库更偏向cross-target化合物"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68042494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5: Known Target Distribution Analysis / 任务五：已知靶点分布分析\n",
    "print(\"=\" * 60)\n",
    "print(\"Task 5: Known Target Distribution Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load target distribution data / 读取靶点分布数据\n",
    "gpcrsarfari_targets_raw = pd.read_csv(r\"c:\\000000000\\5HT2A\\TargetAnalysis\\01_BasicAnalysis\\all_known_targets_distribution.csv\")\n",
    "chembl_targets_raw = pd.read_csv(r\"c:\\000000000\\5HT2A_M3\\TargetAnalysis\\01_BasicAnalysis\\all_known_targets_distribution.csv\")\n",
    "\n",
    "print(f\"Raw Target Distribution Dataset Sizes:\")\n",
    "print(f\"  GPCRSARfari: {len(gpcrsarfari_targets_raw)} target entries\")\n",
    "print(f\"  ChEMBL: {len(chembl_targets_raw)} target entries\")\n",
    "\n",
    "# Define invalid target patterns to exclude / 定义要排除的无效靶点模式\n",
    "invalid_patterns = [\n",
    "    'unchecked', 'others', 'rattus norvegicus', 'mus musculus', 'plasmodium falciparum',\n",
    "    'hepg2', 'homo sapiens', 'saccharomyces cerevisiae', 'escherichia coli',\n",
    "    'cell line', 'species', 'organism', 'unknown', 'unspecified', 'hela',\n",
    "    'mcf-7', 'pc-3', 'a549', 'hek293', 'jurkat', 'k562', 'u937'\n",
    "]\n",
    "\n",
    "def filter_valid_targets(df, target_col='all_known_targets'):\n",
    "    \"\"\"Filter out invalid targets (species names, cell lines, etc.) / 过滤掉无效靶点（物种名、细胞系等）\"\"\"\n",
    "    \n",
    "    # Create a copy to avoid modifying original / 创建副本避免修改原始数据\n",
    "    df_filtered = df.copy()\n",
    "    \n",
    "    # Convert target names to lowercase for case-insensitive matching / 转换为小写进行大小写不敏感匹配\n",
    "    target_lower = df_filtered[target_col].str.lower().str.strip()\n",
    "    \n",
    "    # Create mask for valid targets / 创建有效靶点的掩码\n",
    "    valid_mask = pd.Series([True] * len(df_filtered), index=df_filtered.index)\n",
    "    \n",
    "    # Apply filters / 应用过滤器\n",
    "    for pattern in invalid_patterns:\n",
    "        pattern_mask = ~target_lower.str.contains(pattern, na=False)\n",
    "        valid_mask = valid_mask & pattern_mask\n",
    "    \n",
    "    # Additional specific filters / 额外的特定过滤器\n",
    "    # Remove entries that are too generic or clearly non-target related\n",
    "    generic_patterns = [\n",
    "        r'^\\s*others?\\s*$',  # Just \"others\" or \"other\"\n",
    "        r'^\\s*unchecked\\s*$',  # Just \"unchecked\"\n",
    "        r'^\\s*unknown\\s*$',   # Just \"unknown\"\n",
    "    ]\n",
    "    \n",
    "    for pattern in generic_patterns:\n",
    "        pattern_mask = ~target_lower.str.match(pattern, na=False)\n",
    "        valid_mask = valid_mask & pattern_mask\n",
    "    \n",
    "    df_filtered = df_filtered[valid_mask]\n",
    "    \n",
    "    return df_filtered, len(df) - len(df_filtered)\n",
    "\n",
    "# Filter invalid targets / 过滤无效靶点\n",
    "gpcrsarfari_targets, gpcr_removed = filter_valid_targets(gpcrsarfari_targets_raw)\n",
    "chembl_targets, chembl_removed = filter_valid_targets(chembl_targets_raw)\n",
    "\n",
    "print(f\"\\nFiltered Target Distribution Dataset Sizes:\")\n",
    "print(f\"  GPCRSARfari: {len(gpcrsarfari_targets)} valid targets ({gpcr_removed} invalid targets removed)\")\n",
    "print(f\"  ChEMBL: {len(chembl_targets)} valid targets ({chembl_removed} invalid targets removed)\")\n",
    "\n",
    "print(f\"\\nRemoved invalid targets include:\")\n",
    "removed_gpcr = gpcrsarfari_targets_raw[~gpcrsarfari_targets_raw.index.isin(gpcrsarfari_targets.index)]\n",
    "removed_chembl = chembl_targets_raw[~chembl_targets_raw.index.isin(chembl_targets.index)]\n",
    "print(\"GPCRSARfari removed:\", removed_gpcr['all_known_targets'].tolist())\n",
    "print(\"ChEMBL removed:\", removed_chembl['all_known_targets'].tolist())\n",
    "\n",
    "# Display basic statistics / 显示基本统计\n",
    "print(f\"\\nGPCRSARfari Target Distribution:\")\n",
    "print(gpcrsarfari_targets.head())\n",
    "\n",
    "print(f\"\\nChEMBL Target Distribution:\")\n",
    "print(chembl_targets.head())\n",
    "\n",
    "# Analyze target diversity / 分析靶点多样性\n",
    "def analyze_target_distribution(df, dataset_name):\n",
    "    \"\"\"Analyze target distribution for a dataset (using filtered valid targets) / 分析数据集的靶点分布（使用过滤后的有效靶点）\"\"\"\n",
    "    \n",
    "    # Use the correct column names based on the actual data structure / 根据实际数据结构使用正确的列名\n",
    "    target_col = 'all_known_targets'  # This is the actual column name\n",
    "    count_col = 'Count'  # This is the actual column name\n",
    "    \n",
    "    # Calculate diversity metrics / 计算多样性指标\n",
    "    total_targets = len(df)\n",
    "    total_compounds = df[count_col].sum() if count_col in df.columns else len(df)\n",
    "    \n",
    "    # Top targets / 顶级靶点\n",
    "    top_10_targets = df.nlargest(10, count_col) if count_col in df.columns else df.head(10)\n",
    "    \n",
    "    # Target distribution entropy / 靶点分布熵\n",
    "    if count_col in df.columns:\n",
    "        target_counts = df[count_col].values\n",
    "        # Normalize for entropy calculation / 为熵计算归一化\n",
    "        probabilities = target_counts / target_counts.sum()\n",
    "        target_entropy = entropy(probabilities, base=2)\n",
    "    else:\n",
    "        target_entropy = np.log2(total_targets)  # Maximum entropy if uniform\n",
    "    \n",
    "    # Gini coefficient for target inequality / 靶点不平等的基尼系数\n",
    "    if count_col in df.columns:\n",
    "        sorted_counts = np.sort(target_counts)\n",
    "        n = len(sorted_counts)\n",
    "        index = np.arange(1, n + 1)\n",
    "        gini = ((2 * index - n - 1) * sorted_counts).sum() / (n * sorted_counts.sum())\n",
    "    else:\n",
    "        gini = 0  # Perfect equality if no count data\n",
    "    \n",
    "    return {\n",
    "        'dataset_name': dataset_name,\n",
    "        'total_targets': total_targets,\n",
    "        'total_compounds': total_compounds,\n",
    "        'target_entropy': target_entropy,\n",
    "        'gini_coefficient': gini,\n",
    "        'top_targets': top_10_targets,\n",
    "        'target_column': target_col,\n",
    "        'count_column': count_col\n",
    "    }\n",
    "\n",
    "gpcrsarfari_target_analysis = analyze_target_distribution(gpcrsarfari_targets, 'GPCRSARfari')\n",
    "chembl_target_analysis = analyze_target_distribution(chembl_targets, 'ChEMBL')\n",
    "\n",
    "print(f\"\\nTarget Distribution Analysis:\")\n",
    "print(f\"GPCRSARfari Dataset:\")\n",
    "print(f\"  Total Targets: {gpcrsarfari_target_analysis['total_targets']}\")\n",
    "print(f\"  Total Compounds: {gpcrsarfari_target_analysis['total_compounds']}\")\n",
    "print(f\"  Target Entropy: {gpcrsarfari_target_analysis['target_entropy']:.3f}\")\n",
    "print(f\"  Gini Coefficient: {gpcrsarfari_target_analysis['gini_coefficient']:.3f}\")\n",
    "\n",
    "print(f\"\\nChEMBL Dataset:\")\n",
    "print(f\"  Total Targets: {chembl_target_analysis['total_targets']}\")\n",
    "print(f\"  Total Compounds: {chembl_target_analysis['total_compounds']}\")\n",
    "print(f\"  Target Entropy: {chembl_target_analysis['target_entropy']:.3f}\")\n",
    "print(f\"  Gini Coefficient: {chembl_target_analysis['gini_coefficient']:.3f}\")\n",
    "\n",
    "# Create comprehensive visualization / 创建综合可视化\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "# Create grid layout / 创建网格布局\n",
    "gs = plt.GridSpec(3, 3, figure=fig)\n",
    "\n",
    "# 1. Target count comparison / 靶点数量对比\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "datasets = ['GPCRSARfari', 'ChEMBL']\n",
    "target_counts = [gpcrsarfari_target_analysis['total_targets'], \n",
    "                chembl_target_analysis['total_targets']]\n",
    "compound_counts = [gpcrsarfari_target_analysis['total_compounds'],\n",
    "                  chembl_target_analysis['total_compounds']]\n",
    "\n",
    "x = np.arange(len(datasets))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, target_counts, width, label='Total Targets', alpha=0.7, color='skyblue')\n",
    "ax1_twin = ax1.twinx()\n",
    "bars2 = ax1_twin.bar(x + width/2, compound_counts, width, label='Total Compounds', alpha=0.7, color='lightcoral')\n",
    "\n",
    "ax1.set_ylabel('Number of Targets', color='skyblue')\n",
    "ax1_twin.set_ylabel('Number of Compounds', color='lightcoral')\n",
    "ax1.set_title('Target vs Compound Count')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(datasets)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value annotations / 添加数值标注\n",
    "for i, (targets, compounds) in enumerate(zip(target_counts, compound_counts)):\n",
    "    ax1.annotate(f'{targets}', xy=(i - width/2, targets), xytext=(0, 3), \n",
    "                textcoords=\"offset points\", ha='center', va='bottom', fontweight='bold')\n",
    "    ax1_twin.annotate(f'{compounds}', xy=(i + width/2, compounds), xytext=(0, 3), \n",
    "                     textcoords=\"offset points\", ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Diversity metrics comparison / 多样性度量对比\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "entropies = [gpcrsarfari_target_analysis['target_entropy'], \n",
    "            chembl_target_analysis['target_entropy']]\n",
    "gini_coeffs = [gpcrsarfari_target_analysis['gini_coefficient'],\n",
    "               chembl_target_analysis['gini_coefficient']]\n",
    "\n",
    "x = np.arange(len(datasets))\n",
    "width = 0.35\n",
    "\n",
    "bars3 = ax2.bar(x - width/2, entropies, width, label='Target Entropy', alpha=0.7, color='lightgreen')\n",
    "ax2_twin = ax2.twinx()\n",
    "bars4 = ax2_twin.bar(x + width/2, gini_coeffs, width, label='Gini Coefficient', alpha=0.7, color='orange')\n",
    "\n",
    "ax2.set_ylabel('Entropy', color='lightgreen')\n",
    "ax2_twin.set_ylabel('Gini Coefficient', color='orange')\n",
    "ax2.set_title('Target Distribution Diversity')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(datasets)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "for i, (entropy_val, gini) in enumerate(zip(entropies, gini_coeffs)):\n",
    "    ax2.annotate(f'{entropy_val:.2f}', xy=(i - width/2, entropy_val), xytext=(0, 3), \n",
    "                textcoords=\"offset points\", ha='center', va='bottom', fontweight='bold')\n",
    "    ax2_twin.annotate(f'{gini:.3f}', xy=(i + width/2, gini), xytext=(0, 3), \n",
    "                     textcoords=\"offset points\", ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. Top targets for GPCRSARfari / GPCRSARfari前几名靶点\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "gpcr_top = gpcrsarfari_target_analysis['top_targets']\n",
    "count_col_gpcr = gpcrsarfari_target_analysis['count_column']\n",
    "\n",
    "if count_col_gpcr in gpcr_top.columns and len(gpcr_top) > 0:\n",
    "    y_pos = range(len(gpcr_top))\n",
    "    ax3.barh(y_pos, gpcr_top[count_col_gpcr].values[::-1], alpha=0.7, color='skyblue')\n",
    "    ax3.set_yticks(y_pos)\n",
    "    ax3.set_yticklabels([f'Target {i+1}' for i in range(len(gpcr_top))][::-1])\n",
    "    ax3.set_xlabel('Compound Count')\n",
    "    ax3.set_title('Top 10 Targets - GPCRSARfari')\n",
    "else:\n",
    "    ax3.text(0.5, 0.5, 'No count data available', \n",
    "            ha='center', va='center', transform=ax3.transAxes)\n",
    "    ax3.set_title('Top Targets - GPCRSARfari')\n",
    "\n",
    "# 4. Top targets for ChEMBL / ChEMBL前几名靶点  \n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "chembl_top = chembl_target_analysis['top_targets']\n",
    "count_col_chembl = chembl_target_analysis['count_column']\n",
    "\n",
    "if count_col_chembl in chembl_top.columns and len(chembl_top) > 0:\n",
    "    y_pos = range(len(chembl_top))\n",
    "    ax4.barh(y_pos, chembl_top[count_col_chembl].values[::-1], alpha=0.7, color='lightcoral')\n",
    "    ax4.set_yticks(y_pos)\n",
    "    ax4.set_yticklabels([f'Target {i+1}' for i in range(len(chembl_top))][::-1])\n",
    "    ax4.set_xlabel('Compound Count')\n",
    "    ax4.set_title('Top 10 Targets - ChEMBL')\n",
    "else:\n",
    "    ax4.text(0.5, 0.5, 'No count data available', \n",
    "            ha='center', va='center', transform=ax4.transAxes)\n",
    "    ax4.set_title('Top Targets - ChEMBL')\n",
    "\n",
    "# 5. Target overlap analysis / 靶点重叠分析\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "target_col_gpcr = gpcrsarfari_target_analysis['target_column']\n",
    "target_col_chembl = chembl_target_analysis['target_column']\n",
    "\n",
    "gpcr_targets_set = set(gpcrsarfari_targets[target_col_gpcr].values)\n",
    "chembl_targets_set = set(chembl_targets[target_col_chembl].values)\n",
    "\n",
    "overlap_targets = len(gpcr_targets_set.intersection(chembl_targets_set))\n",
    "gpcr_only = len(gpcr_targets_set - chembl_targets_set)\n",
    "chembl_only = len(chembl_targets_set - gpcr_targets_set)\n",
    "\n",
    "# Manual Venn diagram representation\n",
    "venn_data = [gpcr_only, overlap_targets, chembl_only]\n",
    "venn_labels = ['GPCRSARfari\\nOnly', 'Shared', 'ChEMBL\\nOnly']\n",
    "colors_venn = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "\n",
    "bars5 = ax5.bar(venn_labels, venn_data, color=colors_venn, alpha=0.7)\n",
    "ax5.set_ylabel('Number of Targets')\n",
    "ax5.set_title('Target Overlap Analysis')\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "for i, val in enumerate(venn_data):\n",
    "    ax5.annotate(f'{val}', xy=(i, val), xytext=(0, 3), \n",
    "                textcoords=\"offset points\", ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 6. Jaccard similarity / Jaccard相似性\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "jaccard_similarity = overlap_targets / len(gpcr_targets_set.union(chembl_targets_set))\n",
    "\n",
    "ax6.bar(['Jaccard\\nSimilarity'], [jaccard_similarity], color='gold', alpha=0.7, width=0.5)\n",
    "ax6.set_ylabel('Similarity Score')\n",
    "ax6.set_title('Target Jaccard Similarity')\n",
    "ax6.set_ylim(0, 1)\n",
    "ax6.grid(True, alpha=0.3)\n",
    "ax6.annotate(f'{jaccard_similarity:.3f}', xy=(0, jaccard_similarity), xytext=(0, 3), \n",
    "            textcoords=\"offset points\", ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 7. Distribution comparison pie charts / 分布对比饼图\n",
    "ax7 = fig.add_subplot(gs[2, 0])\n",
    "if count_col_gpcr in gpcr_top.columns and len(gpcr_top) >= 5:\n",
    "    pie_data_gpcr = gpcr_top[count_col_gpcr].head(5).values\n",
    "    pie_labels_gpcr = [f'T{i+1}' for i in range(len(pie_data_gpcr))]\n",
    "    ax7.pie(pie_data_gpcr, labels=pie_labels_gpcr, autopct='%1.1f%%', startangle=90)\n",
    "    ax7.set_title('Top 5 Target Distribution - GPCRSARfari')\n",
    "else:\n",
    "    ax7.text(0.5, 0.5, 'Insufficient data\\nfor pie chart', \n",
    "            ha='center', va='center', transform=ax7.transAxes)\n",
    "    ax7.set_title('Target Distribution - GPCRSARfari')\n",
    "\n",
    "ax8 = fig.add_subplot(gs[2, 1])\n",
    "if count_col_chembl in chembl_top.columns and len(chembl_top) >= 5:\n",
    "    pie_data_chembl = chembl_top[count_col_chembl].head(5).values\n",
    "    pie_labels_chembl = [f'T{i+1}' for i in range(len(pie_data_chembl))]\n",
    "    ax8.pie(pie_data_chembl, labels=pie_labels_chembl, autopct='%1.1f%%', startangle=90)\n",
    "    ax8.set_title('Top 5 Target Distribution - ChEMBL')\n",
    "else:\n",
    "    ax8.text(0.5, 0.5, 'Insufficient data\\nfor pie chart', \n",
    "            ha='center', va='center', transform=ax8.transAxes)\n",
    "    ax8.set_title('Target Distribution - ChEMBL')\n",
    "\n",
    "# 8. Summary statistics table / 汇总统计表\n",
    "ax9 = fig.add_subplot(gs[2, 2])\n",
    "ax9.axis('tight')\n",
    "ax9.axis('off')\n",
    "\n",
    "summary_data = [\n",
    "    ['Total Targets', gpcrsarfari_target_analysis['total_targets'], \n",
    "     chembl_target_analysis['total_targets']],\n",
    "    ['Total Compounds', gpcrsarfari_target_analysis['total_compounds'],\n",
    "     chembl_target_analysis['total_compounds']],\n",
    "    ['Target Entropy', f\"{gpcrsarfari_target_analysis['target_entropy']:.3f}\",\n",
    "     f\"{chembl_target_analysis['target_entropy']:.3f}\"],\n",
    "    ['Gini Coefficient', f\"{gpcrsarfari_target_analysis['gini_coefficient']:.3f}\",\n",
    "     f\"{chembl_target_analysis['gini_coefficient']:.3f}\"],\n",
    "    ['Shared Targets', overlap_targets, overlap_targets],\n",
    "    ['Jaccard Similarity', f\"{jaccard_similarity:.3f}\", f\"{jaccard_similarity:.3f}\"]\n",
    "]\n",
    "\n",
    "table = ax9.table(cellText=summary_data,\n",
    "                  colLabels=['Metric', 'GPCRSARfari', 'ChEMBL'],\n",
    "                  cellLoc='center',\n",
    "                  loc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1.2, 1.5)\n",
    "ax9.set_title('Summary Statistics', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save to task-specific directory / 保存到任务专用目录\n",
    "task5_dir = task_dirs['task5']\n",
    "fig.savefig(task5_dir / 'target_distribution_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save detailed analysis to CSV / 保存详细分析到CSV\n",
    "target_summary = {\n",
    "    'Dataset': ['GPCRSARfari', 'ChEMBL'],\n",
    "    'Total_Targets': [gpcrsarfari_target_analysis['total_targets'], \n",
    "                     chembl_target_analysis['total_targets']],\n",
    "    'Total_Compounds': [gpcrsarfari_target_analysis['total_compounds'],\n",
    "                       chembl_target_analysis['total_compounds']],\n",
    "    'Target_Entropy': [gpcrsarfari_target_analysis['target_entropy'],\n",
    "                      chembl_target_analysis['target_entropy']],\n",
    "    'Gini_Coefficient': [gpcrsarfari_target_analysis['gini_coefficient'],\n",
    "                        chembl_target_analysis['gini_coefficient']],\n",
    "    'Shared_Targets': [overlap_targets, overlap_targets],\n",
    "    'Jaccard_Similarity': [jaccard_similarity, jaccard_similarity]\n",
    "}\n",
    "target_df = pd.DataFrame(target_summary)\n",
    "target_df.to_csv(task5_dir / 'target_distribution_summary.csv', index=False)\n",
    "\n",
    "# Save overlap analysis / 保存重叠分析\n",
    "overlap_analysis = {\n",
    "    'Category': ['GPCRSARfari_Only', 'Shared_Targets', 'ChEMBL_Only', 'Total_Unique'],\n",
    "    'Count': [gpcr_only, overlap_targets, chembl_only, \n",
    "             len(gpcr_targets_set.union(chembl_targets_set))]\n",
    "}\n",
    "overlap_df = pd.DataFrame(overlap_analysis)\n",
    "overlap_df.to_csv(task5_dir / 'target_overlap_analysis.csv', index=False)\n",
    "\n",
    "# Save top targets / 保存顶级靶点\n",
    "try:\n",
    "    gpcrsarfari_target_analysis['top_targets'].to_csv(task5_dir / 'gpcrsarfari_top_targets.csv', index=True)\n",
    "    chembl_target_analysis['top_targets'].to_csv(task5_dir / 'chembl_top_targets.csv', index=True)\n",
    "    print(\"   - gpcrsarfari_top_targets.csv\")\n",
    "    print(\"   - chembl_top_targets.csv\")\n",
    "except PermissionError:\n",
    "    print(\"   - Warning: Could not save top targets CSV files (files may be open)\")\n",
    "    print(\"   - Top targets data is available in memory for analysis\")\n",
    "\n",
    "print(f\"\\nFiles saved to: {task5_dir}\")\n",
    "print(\"   - target_distribution_analysis.png\")\n",
    "print(\"   - target_distribution_summary.csv\")\n",
    "print(\"   - target_overlap_analysis.csv\")\n",
    "print(\"   - gpcrsarfari_top_targets.csv\")\n",
    "print(\"   - chembl_top_targets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485ca25a",
   "metadata": {},
   "source": [
    "## Task 6: Overlap Analysis - Overlap vs Complementarity\n",
    "## 任务六：交集分析 (Overlap Analysis) - 重叠 vs 互补\n",
    "\n",
    "**Analysis Objective** / **分析目标**: Analyze overlapping compounds through SMILES comparison to evaluate whether combined use of both datasets is recommended / 通过SMILES对比分析两数据集的重叠化合物，评估是否需要结合使用两数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990d8029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6: Overlap Analysis / 任务六：重叠分析\n",
    "print(\"=\" * 60)\n",
    "print(\"Task 6: Comprehensive Overlap Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load main datasets / 读取主要数据集\n",
    "gpcrsarfari_data = pd.read_csv(r\"c:\\000000000\\5HT2A\\Final_Filtered_models_with_ChemBL.csv\")\n",
    "chembl_data = pd.read_csv(r\"c:\\000000000\\5HT2A_M3\\Final_Filtered_models_with_ChemBL.csv\")\n",
    "\n",
    "print(f\"Dataset Information:\")\n",
    "print(f\"  GPCRSARfari: {len(gpcrsarfari_data)} compounds\")\n",
    "print(f\"  ChEMBL: {len(chembl_data)} compounds\")\n",
    "\n",
    "# Use SMILES as the compound identifier / 使用SMILES作为化合物标识符\n",
    "gpcr_id_col = 'smiles'\n",
    "chembl_id_col = 'smiles'\n",
    "\n",
    "print(f\"\\nUsing SMILES as compound identifier:\")\n",
    "print(f\"  GPCRSARfari: {gpcr_id_col}\")\n",
    "print(f\"  ChEMBL: {chembl_id_col}\")\n",
    "\n",
    "# Extract compound identifiers using SMILES / 使用SMILES提取化合物标识符\n",
    "gpcr_compounds = set(gpcrsarfari_data[gpcr_id_col].dropna().astype(str).str.strip())\n",
    "chembl_compounds = set(chembl_data[chembl_id_col].dropna().astype(str).str.strip())\n",
    "\n",
    "# Remove any NaN values / 移除任何NaN值\n",
    "gpcr_compounds = {x for x in gpcr_compounds if x != 'nan' and x != ''}\n",
    "chembl_compounds = {x for x in chembl_compounds if x != 'nan' and x != ''}\n",
    "\n",
    "print(f\"\\nValid compound counts after cleaning:\")\n",
    "print(f\"  GPCRSARfari: {len(gpcr_compounds)} unique compounds\")\n",
    "print(f\"  ChEMBL: {len(chembl_compounds)} unique compounds\")\n",
    "\n",
    "# Calculate overlap metrics / 计算重叠度量\n",
    "overlap_compounds = gpcr_compounds.intersection(chembl_compounds)\n",
    "gpcr_only = gpcr_compounds - chembl_compounds\n",
    "chembl_only = chembl_compounds - gpcr_compounds\n",
    "total_unique = gpcr_compounds.union(chembl_compounds)\n",
    "\n",
    "# Overlap statistics / 重叠统计\n",
    "overlap_count = len(overlap_compounds)\n",
    "gpcr_only_count = len(gpcr_only)\n",
    "chembl_only_count = len(chembl_only)\n",
    "total_unique_count = len(total_unique)\n",
    "\n",
    "# Similarity metrics / 相似性度量\n",
    "jaccard_similarity = overlap_count / total_unique_count if total_unique_count > 0 else 0\n",
    "dice_coefficient = (2 * overlap_count) / (len(gpcr_compounds) + len(chembl_compounds))\n",
    "overlap_coefficient = overlap_count / min(len(gpcr_compounds), len(chembl_compounds))\n",
    "\n",
    "print(f\"\\nCompound Overlap Analysis:\")\n",
    "print(f\"  Shared Compounds: {overlap_count}\")\n",
    "print(f\"  GPCRSARfari Only: {gpcr_only_count}\")\n",
    "print(f\"  ChEMBL Only: {chembl_only_count}\")\n",
    "print(f\"  Total Unique Compounds: {total_unique_count}\")\n",
    "\n",
    "print(f\"\\nSimilarity Metrics:\")\n",
    "print(f\"  Jaccard Similarity: {jaccard_similarity:.4f}\")\n",
    "print(f\"  Dice Coefficient: {dice_coefficient:.4f}\")\n",
    "print(f\"  Overlap Coefficient: {overlap_coefficient:.4f}\")\n",
    "\n",
    "# Load clustering data for additional analysis / 读取聚类数据进行额外分析\n",
    "try:\n",
    "    gpcr_clusters = pd.read_csv(r\"c:\\000000000\\5HT2A\\TargetAnalysis\\03_KMeansClustering\\chemical_clusters_kmeans.csv\")\n",
    "    chembl_clusters = pd.read_csv(r\"c:\\000000000\\5HT2A_M3\\TargetAnalysis\\03_KMeansClustering\\chemical_clusters_kmeans.csv\")\n",
    "    \n",
    "    print(f\"\\nChemical Cluster Information:\")\n",
    "    print(f\"  GPCRSARfari clusters: {len(gpcr_clusters)} entries\")\n",
    "    print(f\"  ChEMBL clusters: {len(chembl_clusters)} entries\")\n",
    "    \n",
    "    cluster_analysis_available = True\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nChemical cluster data not available\")\n",
    "    cluster_analysis_available = False\n",
    "\n",
    "# Create comprehensive visualization / 创建综合可视化\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "gs = plt.GridSpec(4, 3, figure=fig)\n",
    "\n",
    "# 1. Main overlap Venn diagram representation / 主要重叠维恩图表示\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "venn_data = [gpcr_only_count, overlap_count, chembl_only_count]\n",
    "venn_labels = ['GPCRSARfari\\nOnly', 'Shared', 'ChEMBL\\nOnly']\n",
    "colors_venn = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "\n",
    "bars1 = ax1.bar(venn_labels, venn_data, color=colors_venn, alpha=0.7)\n",
    "ax1.set_ylabel('Number of Compounds')\n",
    "ax1.set_title('Compound Overlap Distribution')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "for i, val in enumerate(venn_data):\n",
    "    ax1.annotate(f'{val}', xy=(i, val), xytext=(0, 3), \n",
    "                textcoords=\"offset points\", ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Similarity metrics comparison / 相似性度量对比\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "similarity_metrics = ['Jaccard\\nSimilarity', 'Dice\\nCoefficient', 'Overlap\\nCoefficient']\n",
    "similarity_values = [jaccard_similarity, dice_coefficient, overlap_coefficient]\n",
    "colors_sim = ['gold', 'orange', 'coral']\n",
    "\n",
    "bars2 = ax2.bar(similarity_metrics, similarity_values, color=colors_sim, alpha=0.7)\n",
    "ax2.set_ylabel('Similarity Score')\n",
    "ax2.set_title('Similarity Metrics Comparison')\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "for i, val in enumerate(similarity_values):\n",
    "    ax2.annotate(f'{val:.3f}', xy=(i, val), xytext=(0, 3), \n",
    "                textcoords=\"offset points\", ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. Dataset size comparison / 数据集大小对比\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "datasets = ['GPCRSARfari', 'ChEMBL']\n",
    "dataset_sizes = [len(gpcr_compounds), len(chembl_compounds)]\n",
    "colors_size = ['skyblue', 'lightcoral']\n",
    "\n",
    "bars3 = ax3.bar(datasets, dataset_sizes, color=colors_size, alpha=0.7)\n",
    "ax3.set_ylabel('Number of Unique Compounds')\n",
    "ax3.set_title('Dataset Size Comparison')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "for i, val in enumerate(dataset_sizes):\n",
    "    ax3.annotate(f'{val}', xy=(i, val), xytext=(0, 3), \n",
    "                textcoords=\"offset points\", ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 4. Overlap percentage pie chart\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "pie_data = [gpcr_only_count, overlap_count, chembl_only_count]\n",
    "pie_labels = ['GPCRSARfari Only', 'Shared', 'ChEMBL Only']\n",
    "colors_pie = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "\n",
    "wedges, texts, autotexts = ax4.pie(pie_data, labels=pie_labels, autopct='%1.1f%%', \n",
    "                                  startangle=90, colors=colors_pie)\n",
    "ax4.set_title('Compound Distribution')\n",
    "\n",
    "# 5. Overlap rate by dataset\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "overlap_rates = [\n",
    "    overlap_count / len(gpcr_compounds) * 100 if len(gpcr_compounds) > 0 else 0,\n",
    "    overlap_count / len(chembl_compounds) * 100 if len(chembl_compounds) > 0 else 0\n",
    "]\n",
    "\n",
    "bars5 = ax5.bar(datasets, overlap_rates, color=['skyblue', 'lightcoral'], alpha=0.7)\n",
    "ax5.set_ylabel('Overlap Rate (%)')\n",
    "ax5.set_title('Dataset-Specific Overlap Rates')\n",
    "ax5.set_ylim(0, 100)\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "for i, val in enumerate(overlap_rates):\n",
    "    ax5.annotate(f'{val:.1f}%', xy=(i, val), xytext=(0, 3), \n",
    "                textcoords=\"offset points\", ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 6. Statistical summary table\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "ax6.axis('tight')\n",
    "ax6.axis('off')\n",
    "\n",
    "summary_data = [\n",
    "    ['Total Compounds', len(gpcr_compounds), len(chembl_compounds)],\n",
    "    ['Shared Compounds', overlap_count, overlap_count],\n",
    "    ['Unique to Dataset', gpcr_only_count, chembl_only_count],\n",
    "    ['Overlap Rate (%)', f\"{overlap_rates[0]:.1f}\", f\"{overlap_rates[1]:.1f}\"],\n",
    "    ['Jaccard Similarity', f\"{jaccard_similarity:.4f}\", f\"{jaccard_similarity:.4f}\"],\n",
    "    ['Dice Coefficient', f\"{dice_coefficient:.4f}\", f\"{dice_coefficient:.4f}\"]\n",
    "]\n",
    "\n",
    "table = ax6.table(cellText=summary_data,\n",
    "                  colLabels=['Metric', 'GPCRSARfari', 'ChEMBL'],\n",
    "                  cellLoc='center',\n",
    "                  loc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1.2, 1.5)\n",
    "ax6.set_title('Overlap Statistics Summary', pad=20)\n",
    "\n",
    "# 7-12. Additional analysis if cluster data is available\n",
    "if cluster_analysis_available:\n",
    "    # Cluster overlap analysis\n",
    "    ax7 = fig.add_subplot(gs[2, 0])\n",
    "    \n",
    "    # Assume cluster data has 'cluster' column\n",
    "    if 'cluster' in gpcr_clusters.columns:\n",
    "        gpcr_cluster_counts = gpcr_clusters['cluster'].value_counts()\n",
    "        ax7.bar(range(len(gpcr_cluster_counts)), gpcr_cluster_counts.values, \n",
    "               alpha=0.7, color='skyblue')\n",
    "        ax7.set_xlabel('Cluster ID')\n",
    "        ax7.set_ylabel('Number of Compounds')\n",
    "        ax7.set_title('GPCRSARfari Cluster Distribution')\n",
    "        ax7.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        ax7.text(0.5, 0.5, 'Cluster data format\\nnot recognized', \n",
    "                ha='center', va='center', transform=ax7.transAxes)\n",
    "    \n",
    "    ax8 = fig.add_subplot(gs[2, 1])\n",
    "    if 'cluster' in chembl_clusters.columns:\n",
    "        chembl_cluster_counts = chembl_clusters['cluster'].value_counts()\n",
    "        ax8.bar(range(len(chembl_cluster_counts)), chembl_cluster_counts.values, \n",
    "               alpha=0.7, color='lightcoral')\n",
    "        ax8.set_xlabel('Cluster ID')\n",
    "        ax8.set_ylabel('Number of Compounds')\n",
    "        ax8.set_title('ChEMBL Cluster Distribution')\n",
    "        ax8.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        ax8.text(0.5, 0.5, 'Cluster data format\\nnot recognized', \n",
    "                ha='center', va='center', transform=ax8.transAxes)\n",
    "    \n",
    "    # Cluster diversity comparison\n",
    "    ax9 = fig.add_subplot(gs[2, 2])\n",
    "    cluster_metrics = ['Number of\\nClusters', 'Average Cluster\\nSize']\n",
    "    \n",
    "    if 'cluster' in gpcr_clusters.columns and 'cluster' in chembl_clusters.columns:\n",
    "        gpcr_n_clusters = len(gpcr_cluster_counts)\n",
    "        chembl_n_clusters = len(chembl_cluster_counts)\n",
    "        gpcr_avg_size = gpcr_cluster_counts.mean()\n",
    "        chembl_avg_size = chembl_cluster_counts.mean()\n",
    "        \n",
    "        x = np.arange(len(cluster_metrics))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax9.bar(x - width/2, [gpcr_n_clusters, gpcr_avg_size], width, \n",
    "               label='GPCRSARfari', alpha=0.7, color='skyblue')\n",
    "        ax9.bar(x + width/2, [chembl_n_clusters, chembl_avg_size], width, \n",
    "               label='ChEMBL', alpha=0.7, color='lightcoral')\n",
    "        \n",
    "        ax9.set_ylabel('Count / Value')\n",
    "        ax9.set_title('Cluster Characteristics')\n",
    "        ax9.set_xticks(x)\n",
    "        ax9.set_xticklabels(cluster_metrics)\n",
    "        ax9.legend()\n",
    "        ax9.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        ax9.text(0.5, 0.5, 'Insufficient cluster data', \n",
    "                ha='center', va='center', transform=ax9.transAxes)\n",
    "\n",
    "else:\n",
    "    # Placeholder plots when cluster data is not available\n",
    "    for i, ax_pos in enumerate([(2, 0), (2, 1), (2, 2)]):\n",
    "        ax = fig.add_subplot(gs[ax_pos[0], ax_pos[1]])\n",
    "        ax.text(0.5, 0.5, f'Cluster Analysis\\nNot Available', \n",
    "               ha='center', va='center', transform=ax.transAxes, fontsize=12)\n",
    "        ax.set_title(f'Cluster Analysis {i+1}')\n",
    "\n",
    "# 10. Compound length distribution comparison (if applicable)\n",
    "ax10 = fig.add_subplot(gs[3, 0])\n",
    "if gpcr_id_col == chembl_id_col:  # Same type of identifiers\n",
    "    gpcr_lengths = [len(str(x)) for x in gpcr_compounds]\n",
    "    chembl_lengths = [len(str(x)) for x in chembl_compounds]\n",
    "    \n",
    "    bins = np.arange(min(min(gpcr_lengths), min(chembl_lengths)), \n",
    "                    max(max(gpcr_lengths), max(chembl_lengths)) + 2) - 0.5\n",
    "    \n",
    "    ax10.hist(gpcr_lengths, bins=bins, alpha=0.7, label='GPCRSARfari', color='skyblue')\n",
    "    ax10.hist(chembl_lengths, bins=bins, alpha=0.7, label='ChEMBL', color='lightcoral')\n",
    "    ax10.set_xlabel('Identifier Length')\n",
    "    ax10.set_ylabel('Frequency')\n",
    "    ax10.set_title('Compound ID Length Distribution')\n",
    "    ax10.legend()\n",
    "    ax10.grid(True, alpha=0.3)\n",
    "else:\n",
    "    ax10.text(0.5, 0.5, 'Different ID formats\\nCannot compare lengths', \n",
    "             ha='center', va='center', transform=ax10.transAxes)\n",
    "\n",
    "# 11. Sample overlap compounds\n",
    "ax11 = fig.add_subplot(gs[3, 1])\n",
    "ax11.axis('off')\n",
    "\n",
    "if overlap_compounds:\n",
    "    sample_overlap = list(overlap_compounds)[:10]  # Show first 10\n",
    "    overlap_text = \"Sample Shared Compounds:\\n\\n\"\n",
    "    for i, compound in enumerate(sample_overlap, 1):\n",
    "        overlap_text += f\"{i:2d}. {str(compound)[:20]}{'...' if len(str(compound)) > 20 else ''}\\n\"\n",
    "    \n",
    "    if len(overlap_compounds) > 10:\n",
    "        overlap_text += f\"\\n... and {len(overlap_compounds) - 10} more\"\n",
    "    \n",
    "    ax11.text(0.05, 0.95, overlap_text, transform=ax11.transAxes, \n",
    "             fontsize=10, verticalalignment='top', fontfamily='monospace')\n",
    "else:\n",
    "    ax11.text(0.5, 0.5, 'No overlapping compounds found', \n",
    "             ha='center', va='center', transform=ax11.transAxes)\n",
    "\n",
    "ax11.set_title('Shared Compounds Sample')\n",
    "\n",
    "# 12. Overlap trend analysis\n",
    "ax12 = fig.add_subplot(gs[3, 2])\n",
    "\n",
    "# Create a simple trend visualization\n",
    "categories = ['Dataset 1', 'Intersection', 'Dataset 2', 'Union']\n",
    "values = [len(gpcr_compounds), overlap_count, len(chembl_compounds), total_unique_count]\n",
    "colors_trend = ['lightblue', 'lightgreen', 'lightcoral', 'gold']\n",
    "\n",
    "bars12 = ax12.bar(categories, values, color=colors_trend, alpha=0.7)\n",
    "ax12.set_ylabel('Number of Compounds')\n",
    "ax12.set_title('Set Theory Overview')\n",
    "ax12.grid(True, alpha=0.3)\n",
    "\n",
    "for i, val in enumerate(values):\n",
    "    ax12.annotate(f'{val}', xy=(i, val), xytext=(0, 3), \n",
    "                 textcoords=\"offset points\", ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save to task-specific directory\n",
    "task6_dir = task_dirs['task6']\n",
    "fig.savefig(task6_dir / 'comprehensive_overlap_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save detailed overlap analysis to CSV\n",
    "overlap_summary = {\n",
    "    'Metric': ['GPCRSARfari_Total', 'ChEMBL_Total', 'Shared_Compounds', 'GPCRSARfari_Only', \n",
    "              'ChEMBL_Only', 'Total_Unique', 'Jaccard_Similarity', 'Dice_Coefficient', \n",
    "              'Overlap_Coefficient'],\n",
    "    'Value': [len(gpcr_compounds), len(chembl_compounds), overlap_count, gpcr_only_count,\n",
    "              chembl_only_count, total_unique_count, jaccard_similarity, dice_coefficient,\n",
    "              overlap_coefficient],\n",
    "    'Description': ['Total compounds in GPCRSARfari', 'Total compounds in ChEMBL',\n",
    "                   'Compounds present in both datasets', 'Compounds only in GPCRSARfari',\n",
    "                   'Compounds only in ChEMBL', 'Total unique compounds across both datasets',\n",
    "                   'Jaccard similarity coefficient', 'Dice similarity coefficient',\n",
    "                   'Overlap coefficient (Szymkiewicz-Simpson)']\n",
    "}\n",
    "overlap_df = pd.DataFrame(overlap_summary)\n",
    "overlap_df.to_csv(task6_dir / 'overlap_analysis_summary.csv', index=False)\n",
    "\n",
    "# Save overlapping compounds\n",
    "if overlap_compounds:\n",
    "    overlap_compounds_df = pd.DataFrame(list(overlap_compounds), columns=['Shared_Compound_ID'])\n",
    "    overlap_compounds_df.to_csv(task6_dir / 'shared_compounds_list.csv', index=False)\n",
    "\n",
    "# Save dataset-specific compounds\n",
    "gpcr_only_df = pd.DataFrame(list(gpcr_only), columns=['GPCRSARfari_Only_Compound_ID'])\n",
    "gpcr_only_df.to_csv(task6_dir / 'gpcrsarfari_unique_compounds.csv', index=False)\n",
    "\n",
    "chembl_only_df = pd.DataFrame(list(chembl_only), columns=['ChEMBL_Only_Compound_ID'])\n",
    "chembl_only_df.to_csv(task6_dir / 'chembl_unique_compounds.csv', index=False)\n",
    "\n",
    "print(f\"\\nFiles saved to: {task6_dir}\")\n",
    "print(\"   - comprehensive_overlap_analysis.png\")\n",
    "print(\"   - overlap_analysis_summary.csv\")\n",
    "if overlap_compounds:\n",
    "    print(\"   - shared_compounds_list.csv\")\n",
    "print(\"   - gpcrsarfari_unique_compounds.csv\")\n",
    "print(\"   - chembl_unique_compounds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5285fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Dataset Comparative Analysis Complete\")\n",
    "print(\"=\"*80)\n",
    "print(\"All analysis tasks have been completed and files saved to organized directories.\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mastersproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
